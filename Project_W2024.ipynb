{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisor’s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 20:17:33  410925369 Mod01_Course Overview.mp4\n",
      "2021-04-26 20:10:02   39576695 Mod02_Intro.mp4\n",
      "2021-04-26 20:31:23  302994828 Mod02_Sect01.mp4\n",
      "2021-04-26 20:17:33  416563881 Mod02_Sect02.mp4\n",
      "2021-04-26 20:17:33  318685583 Mod02_Sect03.mp4\n",
      "2021-04-26 20:17:33  255877251 Mod02_Sect04.mp4\n",
      "2021-04-26 20:23:51   99988046 Mod02_Sect05.mp4\n",
      "2021-04-26 20:24:54   50700224 Mod02_WrapUp.mp4\n",
      "2021-04-26 20:26:27   60627667 Mod03_Intro.mp4\n",
      "2021-04-26 20:26:28  272229844 Mod03_Sect01.mp4\n",
      "2021-04-26 20:27:06  309127124 Mod03_Sect02_part1.mp4\n",
      "2021-04-26 20:27:06  195635527 Mod03_Sect02_part2.mp4\n",
      "2021-04-26 20:28:03  123924818 Mod03_Sect02_part3.mp4\n",
      "2021-04-26 20:31:28  171681915 Mod03_Sect03_part1.mp4\n",
      "2021-04-26 20:32:07  285200083 Mod03_Sect03_part2.mp4\n",
      "2021-04-26 20:33:17  105470345 Mod03_Sect03_part3.mp4\n",
      "2021-04-26 20:35:10  157185651 Mod03_Sect04_part1.mp4\n",
      "2021-04-26 20:36:27  187435635 Mod03_Sect04_part2.mp4\n",
      "2021-04-26 20:36:40  280720369 Mod03_Sect04_part3.mp4\n",
      "2021-04-26 20:40:01  443479313 Mod03_Sect05.mp4\n",
      "2021-04-26 20:40:08  234182186 Mod03_Sect06.mp4\n",
      "2021-04-26 20:40:33  207718047 Mod03_Sect07_part1.mp4\n",
      "2021-04-26 20:42:07  125592110 Mod03_Sect07_part2.mp4\n",
      "2021-04-26 20:45:10  508500301 Mod03_Sect07_part3.mp4\n",
      "2021-04-26 20:46:16  320126756 Mod03_Sect08.mp4\n",
      "2021-04-26 20:46:43   41839508 Mod03_WrapUp.mp4\n",
      "2021-04-26 20:46:55   34148489 Mod04_Intro.mp4\n",
      "2021-04-26 20:48:24   84959465 Mod04_Sect01.mp4\n",
      "2021-04-26 20:48:25  345182970 Mod04_Sect02_part1.mp4\n",
      "2021-04-26 20:51:34  218661651 Mod04_Sect02_part2.mp4\n",
      "2021-04-26 20:53:32  430140637 Mod04_Sect02_part3.mp4\n",
      "2021-04-26 20:56:03   22036605 Mod04_WrapUp.mp4\n",
      "2021-04-26 20:57:18   49187118 Mod05_Intro.mp4\n",
      "2021-04-26 20:58:19  245798071 Mod05_Sect01_ver2.mp4\n",
      "2021-04-26 20:58:50  233314835 Mod05_Sect02_part1_ver2.mp4\n",
      "2021-04-26 20:59:14  348545306 Mod05_Sect02_part2.mp4\n",
      "2021-04-26 20:59:17  239142711 Mod05_Sect03_part1.mp4\n",
      "2021-04-26 21:06:04  267533559 Mod05_Sect03_part2.mp4\n",
      "2021-04-26 21:06:06  212502220 Mod05_Sect03_part3.mp4\n",
      "2021-04-26 21:06:48  206317022 Mod05_Sect03_part4_ver2.mp4\n",
      "2021-04-26 21:06:48   60361230 Mod05_WrapUp_ver2.mp4\n",
      "2021-04-26 21:09:14   35397860 Mod06_Intro.mp4\n",
      "2021-04-26 21:09:24  845633599 Mod06_Sect01.mp4\n",
      "2021-04-26 21:10:47  326126684 Mod06_Sect02.mp4\n",
      "2021-04-26 21:12:26   19790740 Mod06_WrapUp.mp4\n",
      "2021-04-26 21:12:56  131249036 Mod07_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect01.mp4 to s3://nlp-project-w2024/Mod02_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect02.mp4 to s3://nlp-project-w2024/Mod02_Sect02.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Intro.mp4 to s3://nlp-project-w2024/Mod02_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_WrapUp.mp4 to s3://nlp-project-w2024/Mod02_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Intro.mp4 to s3://nlp-project-w2024/Mod03_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect03.mp4 to s3://nlp-project-w2024/Mod02_Sect03.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part1.mp4 to s3://nlp-project-w2024/Mod03_Sect02_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect01.mp4 to s3://nlp-project-w2024/Mod03_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part3.mp4 to s3://nlp-project-w2024/Mod03_Sect02_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect05.mp4 to s3://nlp-project-w2024/Mod02_Sect05.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part2.mp4 to s3://nlp-project-w2024/Mod03_Sect03_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part3.mp4 to s3://nlp-project-w2024/Mod03_Sect03_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part1.mp4 to s3://nlp-project-w2024/Mod03_Sect04_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod01_Course Overview.mp4 to s3://nlp-project-w2024/Mod01_Course Overview.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part3.mp4 to s3://nlp-project-w2024/Mod03_Sect04_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod02_Sect04.mp4 to s3://nlp-project-w2024/Mod02_Sect04.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect06.mp4 to s3://nlp-project-w2024/Mod03_Sect06.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect02_part2.mp4 to s3://nlp-project-w2024/Mod03_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part2.mp4 to s3://nlp-project-w2024/Mod03_Sect07_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect03_part1.mp4 to s3://nlp-project-w2024/Mod03_Sect03_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect08.mp4 to s3://nlp-project-w2024/Mod03_Sect08.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_WrapUp.mp4 to s3://nlp-project-w2024/Mod03_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Intro.mp4 to s3://nlp-project-w2024/Mod04_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect04_part2.mp4 to s3://nlp-project-w2024/Mod03_Sect04_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect01.mp4 to s3://nlp-project-w2024/Mod04_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part2.mp4 to s3://nlp-project-w2024/Mod04_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect05.mp4 to s3://nlp-project-w2024/Mod03_Sect05.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part1.mp4 to s3://nlp-project-w2024/Mod03_Sect07_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Intro.mp4 to s3://nlp-project-w2024/Mod05_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect01_ver2.mp4 to s3://nlp-project-w2024/Mod05_Sect01_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part1.mp4 to s3://nlp-project-w2024/Mod04_Sect02_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_WrapUp.mp4 to s3://nlp-project-w2024/Mod04_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod04_Sect02_part3.mp4 to s3://nlp-project-w2024/Mod04_Sect02_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect02_part1_ver2.mp4 to s3://nlp-project-w2024/Mod05_Sect02_part1_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect02_part2.mp4 to s3://nlp-project-w2024/Mod05_Sect02_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod03_Sect07_part3.mp4 to s3://nlp-project-w2024/Mod03_Sect07_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_WrapUp_ver2.mp4 to s3://nlp-project-w2024/Mod05_WrapUp_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Intro.mp4 to s3://nlp-project-w2024/Mod06_Intro.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part1.mp4 to s3://nlp-project-w2024/Mod05_Sect03_part1.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part2.mp4 to s3://nlp-project-w2024/Mod05_Sect03_part2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part3.mp4 to s3://nlp-project-w2024/Mod05_Sect03_part3.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod05_Sect03_part4_ver2.mp4 to s3://nlp-project-w2024/Mod05_Sect03_part4_ver2.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_WrapUp.mp4 to s3://nlp-project-w2024/Mod06_WrapUp.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod07_Sect01.mp4 to s3://nlp-project-w2024/Mod07_Sect01.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Sect02.mp4 to s3://nlp-project-w2024/Mod06_Sect02.mp4\n",
      "copy: s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/Mod06_Sect01.mp4 to s3://nlp-project-w2024/Mod06_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "#Copying videos to S3 Bucket\n",
    "!aws s3 sync s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/ s3://nlp-project-w2024/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy: s3://nlp-project-w2024/Mod02_Sect01.mp4 to s3://nlp-project-w2024/videos/Mod02_Sect01.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_Sect02.mp4 to s3://nlp-project-w2024/videos/Mod02_Sect02.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_Sect05.mp4 to s3://nlp-project-w2024/videos/Mod02_Sect05.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_Intro.mp4 to s3://nlp-project-w2024/videos/Mod02_Intro.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Intro.mp4 to s3://nlp-project-w2024/videos/Mod03_Intro.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect01.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect01.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect02_part1.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect02_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect02_part2.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect02_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect02_part3.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect02_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_Sect04.mp4 to s3://nlp-project-w2024/videos/Mod02_Sect04.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect03_part2.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect03_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect03_part3.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect03_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_WrapUp.mp4 to s3://nlp-project-w2024/videos/Mod02_WrapUp.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect04_part1.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect04_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect03_part1.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect03_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect04_part2.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect04_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod02_Sect03.mp4 to s3://nlp-project-w2024/videos/Mod02_Sect03.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect07_part1.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect07_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod01_Course Overview.mp4 to s3://nlp-project-w2024/videos/Mod01_Course Overview.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect07_part3.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect07_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect04_part3.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect04_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect08.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect08.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect07_part2.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect07_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_Intro.mp4 to s3://nlp-project-w2024/videos/Mod04_Intro.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_Sect01.mp4 to s3://nlp-project-w2024/videos/Mod04_Sect01.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_WrapUp.mp4 to s3://nlp-project-w2024/videos/Mod03_WrapUp.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect06.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect06.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_WrapUp.mp4 to s3://nlp-project-w2024/videos/Mod04_WrapUp.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Intro.mp4 to s3://nlp-project-w2024/videos/Mod05_Intro.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_Sect02_part2.mp4 to s3://nlp-project-w2024/videos/Mod04_Sect02_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod03_Sect05.mp4 to s3://nlp-project-w2024/videos/Mod03_Sect05.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_Sect02_part1.mp4 to s3://nlp-project-w2024/videos/Mod04_Sect02_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect02_part2.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect02_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect03_part1.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect03_part1.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect01_ver2.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect01_ver2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect02_part1_ver2.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect02_part1_ver2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect03_part2.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect03_part2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod06_Intro.mp4 to s3://nlp-project-w2024/videos/Mod06_Intro.mp4\n",
      "copy: s3://nlp-project-w2024/Mod04_Sect02_part3.mp4 to s3://nlp-project-w2024/videos/Mod04_Sect02_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_WrapUp_ver2.mp4 to s3://nlp-project-w2024/videos/Mod05_WrapUp_ver2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod06_WrapUp.mp4 to s3://nlp-project-w2024/videos/Mod06_WrapUp.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect03_part3.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect03_part3.mp4\n",
      "copy: s3://nlp-project-w2024/Mod05_Sect03_part4_ver2.mp4 to s3://nlp-project-w2024/videos/Mod05_Sect03_part4_ver2.mp4\n",
      "copy: s3://nlp-project-w2024/Mod07_Sect01.mp4 to s3://nlp-project-w2024/videos/Mod07_Sect01.mp4\n",
      "copy: s3://nlp-project-w2024/Mod06_Sect02.mp4 to s3://nlp-project-w2024/videos/Mod06_Sect02.mp4\n",
      "copy: s3://nlp-project-w2024/Mod06_Sect01.mp4 to s3://nlp-project-w2024/videos/Mod06_Sect01.mp4\n"
     ]
    }
   ],
   "source": [
    "#Filtering only the videos to different folder\n",
    "!aws s3 sync s3://nlp-project-w2024/ s3://nlp-project-w2024/videos/ --exclude \"*\" --include \"*.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.78)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.78 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.34.78)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.78->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.78->boto3) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.78->boto3) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moviepy\n",
      "  Downloading moviepy-1.0.3.tar.gz (388 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.3/388.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting decorator<5.0,>=4.0.2 (from moviepy)\n",
      "  Downloading decorator-4.4.2-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (2.31.0)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading proglog-0.1.10-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (1.22.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from moviepy) (2.34.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from imageio_ffmpeg>=0.2.0->moviepy) (69.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.2.2)\n",
      "Downloading decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
      "Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-py3-none-any.whl size=110720 sha256=fbdd79154a1beacf46010a7072ade8c7570421fdc85d771b37091f5c932fd6d9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/96/32/2d/e10123bd88fbfc02fed53cc18c80a171d3c87479ed845fa7c1\n",
      "Successfully built moviepy\n",
      "Installing collected packages: proglog, imageio_ffmpeg, decorator, moviepy\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.1.1\n",
      "    Uninstalling decorator-5.1.1:\n",
      "      Successfully uninstalled decorator-5.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed decorator-4.4.2 imageio_ffmpeg-0.4.9 moviepy-1.0.3 proglog-0.1.10\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video files from the bucket...\n",
      "Downloaded: Mod01_Course Overview.mp4 -> downloaded_videos/Mod01_Course Overview.mp4\n",
      "Downloaded: Mod02_Intro.mp4 -> downloaded_videos/Mod02_Intro.mp4\n",
      "Downloaded: Mod02_Sect01.mp4 -> downloaded_videos/Mod02_Sect01.mp4\n",
      "Downloaded: Mod02_Sect02.mp4 -> downloaded_videos/Mod02_Sect02.mp4\n",
      "Downloaded: Mod02_Sect03.mp4 -> downloaded_videos/Mod02_Sect03.mp4\n",
      "Downloaded: Mod02_Sect04.mp4 -> downloaded_videos/Mod02_Sect04.mp4\n",
      "Downloaded: Mod02_Sect05.mp4 -> downloaded_videos/Mod02_Sect05.mp4\n",
      "Downloaded: Mod02_WrapUp.mp4 -> downloaded_videos/Mod02_WrapUp.mp4\n",
      "Downloaded: Mod03_Intro.mp4 -> downloaded_videos/Mod03_Intro.mp4\n",
      "Downloaded: Mod03_Sect01.mp4 -> downloaded_videos/Mod03_Sect01.mp4\n",
      "Downloaded: Mod03_Sect02_part1.mp4 -> downloaded_videos/Mod03_Sect02_part1.mp4\n",
      "Downloaded: Mod03_Sect02_part2.mp4 -> downloaded_videos/Mod03_Sect02_part2.mp4\n",
      "Downloaded: Mod03_Sect02_part3.mp4 -> downloaded_videos/Mod03_Sect02_part3.mp4\n",
      "Downloaded: Mod03_Sect03_part1.mp4 -> downloaded_videos/Mod03_Sect03_part1.mp4\n",
      "Downloaded: Mod03_Sect03_part2.mp4 -> downloaded_videos/Mod03_Sect03_part2.mp4\n",
      "Downloaded: Mod03_Sect03_part3.mp4 -> downloaded_videos/Mod03_Sect03_part3.mp4\n",
      "Downloaded: Mod03_Sect04_part1.mp4 -> downloaded_videos/Mod03_Sect04_part1.mp4\n",
      "Downloaded: Mod03_Sect04_part2.mp4 -> downloaded_videos/Mod03_Sect04_part2.mp4\n",
      "Downloaded: Mod03_Sect04_part3.mp4 -> downloaded_videos/Mod03_Sect04_part3.mp4\n",
      "Downloaded: Mod03_Sect05.mp4 -> downloaded_videos/Mod03_Sect05.mp4\n",
      "Downloaded: Mod03_Sect06.mp4 -> downloaded_videos/Mod03_Sect06.mp4\n",
      "Downloaded: Mod03_Sect07_part1.mp4 -> downloaded_videos/Mod03_Sect07_part1.mp4\n",
      "Downloaded: Mod03_Sect07_part2.mp4 -> downloaded_videos/Mod03_Sect07_part2.mp4\n",
      "Downloaded: Mod03_Sect07_part3.mp4 -> downloaded_videos/Mod03_Sect07_part3.mp4\n",
      "Downloaded: Mod03_Sect08.mp4 -> downloaded_videos/Mod03_Sect08.mp4\n",
      "Downloaded: Mod03_WrapUp.mp4 -> downloaded_videos/Mod03_WrapUp.mp4\n",
      "Downloaded: Mod04_Intro.mp4 -> downloaded_videos/Mod04_Intro.mp4\n",
      "Downloaded: Mod04_Sect01.mp4 -> downloaded_videos/Mod04_Sect01.mp4\n",
      "Downloaded: Mod04_Sect02_part1.mp4 -> downloaded_videos/Mod04_Sect02_part1.mp4\n",
      "Downloaded: Mod04_Sect02_part2.mp4 -> downloaded_videos/Mod04_Sect02_part2.mp4\n",
      "Downloaded: Mod04_Sect02_part3.mp4 -> downloaded_videos/Mod04_Sect02_part3.mp4\n",
      "Downloaded: Mod04_WrapUp.mp4 -> downloaded_videos/Mod04_WrapUp.mp4\n",
      "Downloaded: Mod05_Intro.mp4 -> downloaded_videos/Mod05_Intro.mp4\n",
      "Downloaded: Mod05_Sect01_ver2.mp4 -> downloaded_videos/Mod05_Sect01_ver2.mp4\n",
      "Downloaded: Mod05_Sect02_part1_ver2.mp4 -> downloaded_videos/Mod05_Sect02_part1_ver2.mp4\n",
      "Downloaded: Mod05_Sect02_part2.mp4 -> downloaded_videos/Mod05_Sect02_part2.mp4\n",
      "Downloaded: Mod05_Sect03_part1.mp4 -> downloaded_videos/Mod05_Sect03_part1.mp4\n",
      "Downloaded: Mod05_Sect03_part2.mp4 -> downloaded_videos/Mod05_Sect03_part2.mp4\n",
      "Downloaded: Mod05_Sect03_part3.mp4 -> downloaded_videos/Mod05_Sect03_part3.mp4\n",
      "Downloaded: Mod05_Sect03_part4_ver2.mp4 -> downloaded_videos/Mod05_Sect03_part4_ver2.mp4\n",
      "Downloaded: Mod05_WrapUp_ver2.mp4 -> downloaded_videos/Mod05_WrapUp_ver2.mp4\n",
      "Downloaded: Mod06_Intro.mp4 -> downloaded_videos/Mod06_Intro.mp4\n",
      "Downloaded: Mod06_Sect01.mp4 -> downloaded_videos/Mod06_Sect01.mp4\n",
      "Downloaded: Mod06_Sect02.mp4 -> downloaded_videos/Mod06_Sect02.mp4\n",
      "Downloaded: Mod06_WrapUp.mp4 -> downloaded_videos/Mod06_WrapUp.mp4\n",
      "Downloaded: Mod07_Sect01.mp4 -> downloaded_videos/Mod07_Sect01.mp4\n",
      "Downloaded: videos/Mod01_Course Overview.mp4 -> downloaded_videos/Mod01_Course Overview.mp4\n",
      "Downloaded: videos/Mod02_Intro.mp4 -> downloaded_videos/Mod02_Intro.mp4\n",
      "Downloaded: videos/Mod02_Sect01.mp4 -> downloaded_videos/Mod02_Sect01.mp4\n",
      "Downloaded: videos/Mod02_Sect02.mp4 -> downloaded_videos/Mod02_Sect02.mp4\n",
      "Downloaded: videos/Mod02_Sect03.mp4 -> downloaded_videos/Mod02_Sect03.mp4\n",
      "Downloaded: videos/Mod02_Sect04.mp4 -> downloaded_videos/Mod02_Sect04.mp4\n",
      "Downloaded: videos/Mod02_Sect05.mp4 -> downloaded_videos/Mod02_Sect05.mp4\n",
      "Downloaded: videos/Mod02_WrapUp.mp4 -> downloaded_videos/Mod02_WrapUp.mp4\n",
      "Downloaded: videos/Mod03_Intro.mp4 -> downloaded_videos/Mod03_Intro.mp4\n",
      "Downloaded: videos/Mod03_Sect01.mp4 -> downloaded_videos/Mod03_Sect01.mp4\n",
      "Downloaded: videos/Mod03_Sect02_part1.mp4 -> downloaded_videos/Mod03_Sect02_part1.mp4\n",
      "Downloaded: videos/Mod03_Sect02_part2.mp4 -> downloaded_videos/Mod03_Sect02_part2.mp4\n",
      "Downloaded: videos/Mod03_Sect02_part3.mp4 -> downloaded_videos/Mod03_Sect02_part3.mp4\n",
      "Downloaded: videos/Mod03_Sect03_part1.mp4 -> downloaded_videos/Mod03_Sect03_part1.mp4\n",
      "Downloaded: videos/Mod03_Sect03_part2.mp4 -> downloaded_videos/Mod03_Sect03_part2.mp4\n",
      "Downloaded: videos/Mod03_Sect03_part3.mp4 -> downloaded_videos/Mod03_Sect03_part3.mp4\n",
      "Downloaded: videos/Mod03_Sect04_part1.mp4 -> downloaded_videos/Mod03_Sect04_part1.mp4\n",
      "Downloaded: videos/Mod03_Sect04_part2.mp4 -> downloaded_videos/Mod03_Sect04_part2.mp4\n",
      "Downloaded: videos/Mod03_Sect04_part3.mp4 -> downloaded_videos/Mod03_Sect04_part3.mp4\n",
      "Downloaded: videos/Mod03_Sect05.mp4 -> downloaded_videos/Mod03_Sect05.mp4\n",
      "Downloaded: videos/Mod03_Sect06.mp4 -> downloaded_videos/Mod03_Sect06.mp4\n",
      "Downloaded: videos/Mod03_Sect07_part1.mp4 -> downloaded_videos/Mod03_Sect07_part1.mp4\n",
      "Downloaded: videos/Mod03_Sect07_part2.mp4 -> downloaded_videos/Mod03_Sect07_part2.mp4\n",
      "Downloaded: videos/Mod03_Sect07_part3.mp4 -> downloaded_videos/Mod03_Sect07_part3.mp4\n",
      "Downloaded: videos/Mod03_Sect08.mp4 -> downloaded_videos/Mod03_Sect08.mp4\n",
      "Downloaded: videos/Mod03_WrapUp.mp4 -> downloaded_videos/Mod03_WrapUp.mp4\n",
      "Downloaded: videos/Mod04_Intro.mp4 -> downloaded_videos/Mod04_Intro.mp4\n",
      "Downloaded: videos/Mod04_Sect01.mp4 -> downloaded_videos/Mod04_Sect01.mp4\n",
      "Downloaded: videos/Mod04_Sect02_part1.mp4 -> downloaded_videos/Mod04_Sect02_part1.mp4\n",
      "Downloaded: videos/Mod04_Sect02_part2.mp4 -> downloaded_videos/Mod04_Sect02_part2.mp4\n",
      "Downloaded: videos/Mod04_Sect02_part3.mp4 -> downloaded_videos/Mod04_Sect02_part3.mp4\n",
      "Downloaded: videos/Mod04_WrapUp.mp4 -> downloaded_videos/Mod04_WrapUp.mp4\n",
      "Downloaded: videos/Mod05_Intro.mp4 -> downloaded_videos/Mod05_Intro.mp4\n",
      "Downloaded: videos/Mod05_Sect01_ver2.mp4 -> downloaded_videos/Mod05_Sect01_ver2.mp4\n",
      "Downloaded: videos/Mod05_Sect02_part1_ver2.mp4 -> downloaded_videos/Mod05_Sect02_part1_ver2.mp4\n",
      "Downloaded: videos/Mod05_Sect02_part2.mp4 -> downloaded_videos/Mod05_Sect02_part2.mp4\n",
      "Downloaded: videos/Mod05_Sect03_part1.mp4 -> downloaded_videos/Mod05_Sect03_part1.mp4\n",
      "Downloaded: videos/Mod05_Sect03_part2.mp4 -> downloaded_videos/Mod05_Sect03_part2.mp4\n",
      "Downloaded: videos/Mod05_Sect03_part3.mp4 -> downloaded_videos/Mod05_Sect03_part3.mp4\n",
      "Downloaded: videos/Mod05_Sect03_part4_ver2.mp4 -> downloaded_videos/Mod05_Sect03_part4_ver2.mp4\n",
      "Downloaded: videos/Mod05_WrapUp_ver2.mp4 -> downloaded_videos/Mod05_WrapUp_ver2.mp4\n",
      "Downloaded: videos/Mod06_Intro.mp4 -> downloaded_videos/Mod06_Intro.mp4\n",
      "Downloaded: videos/Mod06_Sect01.mp4 -> downloaded_videos/Mod06_Sect01.mp4\n",
      "Downloaded: videos/Mod06_Sect02.mp4 -> downloaded_videos/Mod06_Sect02.mp4\n",
      "Downloaded: videos/Mod06_WrapUp.mp4 -> downloaded_videos/Mod06_WrapUp.mp4\n",
      "Downloaded: videos/Mod07_Sect01.mp4 -> downloaded_videos/Mod07_Sect01.mp4\n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "bucket_name = 'nlp-project-w2024'\n",
    "\n",
    "bucket_prefix = 'videos/'\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name)\n",
    "if 'Contents' in response:\n",
    "   \n",
    "    print(\"Downloading video files from the bucket...\")\n",
    "\n",
    "    destination_folder = 'downloaded_videos'\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # Download and save videos to the destination folder\n",
    "    for obj in response['Contents']:\n",
    "    \n",
    "        object_key = obj['Key']\n",
    "\n",
    "        # Check if the object is a video file\n",
    "        if object_key.endswith('.mp4'):\n",
    "            \n",
    "            local_video_file = os.path.join(destination_folder, os.path.basename(object_key))\n",
    "            s3_client.download_file(bucket_name, object_key, local_video_file)\n",
    "            print(f\"Downloaded: {object_key} -> {local_video_file}\")\n",
    "\n",
    "    print(\"Download completed.\")\n",
    "else:\n",
    "    print(\"No video files found in the bucket.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted_audios/Mod05_Sect02_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect08.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect03_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod06_Sect02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod07_Sect01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect07_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect03_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_Sect02_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect02_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_Intro.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect01_ver2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect04_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect03_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_Sect02_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Intro.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod06_Sect01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect07_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect04_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Sect05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Sect01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect02_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect02_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Intro.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod01_Course Overview.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect03_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect05.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Sect02.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_WrapUp_ver2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect04_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_Sect01.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect02_part1_ver2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Sect03.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_WrapUp.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_WrapUp.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect03_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod06_WrapUp.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect06.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_Sect04.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod02_WrapUp.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod03_Sect07_part3.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Intro.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod04_Sect02_part1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect03_part4_ver2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod05_Sect03_part2.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in converted_audios/Mod06_Intro.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Conversion of video files to audio files completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Directory containing downloaded video files\n",
    "downloaded_videos_directory = \"downloaded_videos\"\n",
    "\n",
    "# Directory to save converted audio files\n",
    "converted_audios_directory = \"converted_audios\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(converted_audios_directory):\n",
    "    os.makedirs(converted_audios_directory)\n",
    "\n",
    "# Iterate through downloaded video files\n",
    "for root, dirs, files in os.walk(downloaded_videos_directory):\n",
    "    for file in files:\n",
    "        \n",
    "        if file.endswith(\".mp4\"):\n",
    "            \n",
    "            video_path = os.path.join(root, file)\n",
    "            \n",
    "            \n",
    "            video_clip = VideoFileClip(video_path)\n",
    "            \n",
    "            audio_clip = video_clip.audio\n",
    "            \n",
    "            \n",
    "            output_audio_path = os.path.join(converted_audios_directory, os.path.splitext(file)[0] + \".wav\")\n",
    "            \n",
    "            audio_clip.write_audiofile(output_audio_path, codec='mp3')  # Specify the codec as mp3\n",
    "            \n",
    "            video_clip.close()\n",
    "\n",
    "print(\"Conversion of video files to audio files completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-speech in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.26.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.18.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-cloud-speech) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-cloud-speech) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-cloud-speech) (4.25.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.62.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (1.62.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-speech) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-speech) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\n",
      "  Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n",
      "Downloading SpeechRecognition-3.10.3-py2.py3-none-any.whl (32.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
      "Successfully installed SpeechRecognition-3.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::autopep8==2.0.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::black==24.2.0=py310hff52083_0\n",
      "  - conda-forge/noarch::bleach==6.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::plotly==5.19.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytest==8.0.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::qtpy==2.4.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::sip==6.7.12=py310hc6cd4ac_0\n",
      "  - conda-forge/noarch::tqdm==4.66.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask==3.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==7.0.1=hd8ed1ab_0\n",
      "  - conda-forge/noarch::nltk==3.8.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt5-sip==12.12.2=py310hc6cd4ac_5\n",
      "  - conda-forge/noarch::pytoolconfig==1.2.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qdarkstyle==3.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtawesome==1.3.0=pyh9208f05_0\n",
      "  - conda-forge/noarch::yapf==0.40.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask-core==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask-cors==4.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_client==8.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.17.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::rope==1.12.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::s3transfer==0.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::distributed==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipykernel==6.29.2=pyhd33586a_0\n",
      "  - conda-forge/linux-64::keyring==24.3.0=py310hff52083_0\n",
      "  - conda-forge/noarch::python-lsp-server==1.7.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::imagecodecs==2024.1.1=py310h496a806_0\n",
      "  - conda-forge/noarch::jupyter_console==6.6.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt==5.15.9=py310h04931ad_5\n",
      "  - conda-forge/noarch::python-lsp-black==2.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtconsole-base==5.4.4=pyha770c72_0\n",
      "  - conda-forge/noarch::spyder-kernels==2.4.4=unix_pyh707e725_0\n",
      "  - conda-forge/linux-64::astropy==6.0.0=py310h1f7b6fc_0\n",
      "  - conda-forge/noarch::bokeh==3.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.8.3=py310h62c0568_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqtwebengine==5.15.9=py310h704022c_5\n",
      "  - conda-forge/linux-64::pytables==3.9.2=py310h374b01c_1\n",
      "  - conda-forge/noarch::qtconsole==5.4.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::statsmodels==0.14.1=py310h1f7b6fc_0\n",
      "  - conda-forge/noarch::tifffile==2024.2.12=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_server==2.12.5=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.8.3=py310hff52083_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::scikit-image==0.22.0=py310hcc13569_2\n",
      "  - conda-forge/noarch::seaborn-base==0.13.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::shap==0.44.0=cpu_py310h7af0403_7\n",
      "  - conda-forge/noarch::jupyter-lsp==2.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.25.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert==7.16.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn==0.13.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==4.1.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==7.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2024.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter==1.0.0=pyhd8ed1ab_10\n",
      "  - conda-forge/noarch::hdijupyterutils==0.21.0=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::autovizwidget==0.21.0=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::sparkmagic==0.21.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::numpydoc==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::spyder==5.4.5=py310hff52083_0\n",
      "  - conda-forge/noarch::sphinxcontrib-applehelp==1.0.8=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-devhelp==1.0.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-htmlhelp==2.0.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-qthelp==1.0.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinx==7.2.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.10=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.7=pyhd8ed1ab_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.3.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.3.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ffmpeg\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    botocore-1.34.84           |pyge310_1234567_0         6.6 MB  conda-forge\n",
      "    c-blosc2-2.12.0            |       hb4ffafa_0         326 KB  conda-forge\n",
      "    ffmpeg-6.1.1               | gpl_h8007c5b_104         9.3 MB  conda-forge\n",
      "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
      "    libass-0.17.1              |       h8fe9dca_1         124 KB  conda-forge\n",
      "    libdrm-2.4.120             |       hd590300_0         296 KB  conda-forge\n",
      "    libopenvino-2023.3.0       |       h2e90f83_1         5.7 MB  conda-forge\n",
      "    libopenvino-auto-batch-plugin-2023.3.0|       hd5fc58b_1         112 KB  conda-forge\n",
      "    libopenvino-auto-plugin-2023.3.0|       hd5fc58b_1         232 KB  conda-forge\n",
      "    libopenvino-hetero-plugin-2023.3.0|       h3ecfda7_1         177 KB  conda-forge\n",
      "    libopenvino-intel-cpu-plugin-2023.3.0|       h2e90f83_1         9.7 MB  conda-forge\n",
      "    libopenvino-intel-gpu-plugin-2023.3.0|       h2e90f83_1         7.8 MB  conda-forge\n",
      "    libopenvino-ir-frontend-2023.3.0|       h3ecfda7_1         194 KB  conda-forge\n",
      "    libopenvino-onnx-frontend-2023.3.0|       hfbc7f12_1         1.5 MB  conda-forge\n",
      "    libopenvino-paddle-frontend-2023.3.0|       hfbc7f12_1         644 KB  conda-forge\n",
      "    libopenvino-pytorch-frontend-2023.3.0|       h59595ed_1         937 KB  conda-forge\n",
      "    libopenvino-tensorflow-frontend-2023.3.0|       h0bff32c_1         1.1 MB  conda-forge\n",
      "    libopenvino-tensorflow-lite-frontend-2023.3.0|       h59595ed_1         448 KB  conda-forge\n",
      "    libpciaccess-0.18          |       hd590300_0          28 KB  conda-forge\n",
      "    libva-2.21.0               |       hd590300_0         185 KB  conda-forge\n",
      "    libvpx-1.13.1              |       h59595ed_0         982 KB  conda-forge\n",
      "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
      "    ocl-icd-2.3.2              |       hd590300_1         133 KB  conda-forge\n",
      "    openh264-2.4.1             |       h59595ed_0         718 KB  conda-forge\n",
      "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
      "    pugixml-1.14               |       h59595ed_0         112 KB  conda-forge\n",
      "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
      "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        58.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  botocore           conda-forge/noarch::botocore-1.34.84-pyge310_1234567_0 \n",
      "  cloudpickle        conda-forge/noarch::cloudpickle-3.0.0-pyhd8ed1ab_0 \n",
      "  colorama           conda-forge/noarch::colorama-0.4.6-pyhd8ed1ab_0 \n",
      "  docutils           conda-forge/linux-64::docutils-0.20.1-py310hff52083_3 \n",
      "  ffmpeg             conda-forge/linux-64::ffmpeg-6.1.1-gpl_h8007c5b_104 \n",
      "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-7.1.0-pyha770c72_0 \n",
      "  libass             conda-forge/linux-64::libass-0.17.1-h8fe9dca_1 \n",
      "  libdrm             conda-forge/linux-64::libdrm-2.4.120-hd590300_0 \n",
      "  libidn2            conda-forge/linux-64::libidn2-2.3.7-hd590300_0 \n",
      "  libopenvino        conda-forge/linux-64::libopenvino-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2023.3.0-hd5fc58b_1 \n",
      "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2023.3.0-hd5fc58b_1 \n",
      "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2023.3.0-h3ecfda7_1 \n",
      "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2023.3.0-h2e90f83_1 \n",
      "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2023.3.0-h3ecfda7_1 \n",
      "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2023.3.0-hfbc7f12_1 \n",
      "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2023.3.0-hfbc7f12_1 \n",
      "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2023.3.0-h59595ed_1 \n",
      "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2023.3.0-h0bff32c_1 \n",
      "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2023.3.0-h59595ed_1 \n",
      "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hd590300_0 \n",
      "  libtasn1           conda-forge/linux-64::libtasn1-4.19.0-h166bdaf_0 \n",
      "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
      "  libva              conda-forge/linux-64::libva-2.21.0-hd590300_0 \n",
      "  libvpx             conda-forge/linux-64::libvpx-1.13.1-h59595ed_0 \n",
      "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
      "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.2-hd590300_1 \n",
      "  openh264           conda-forge/linux-64::openh264-2.4.1-h59595ed_0 \n",
      "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
      "  packaging          conda-forge/noarch::packaging-24.0-pyhd8ed1ab_0 \n",
      "  pugixml            conda-forge/linux-64::pugixml-1.14-h59595ed_0 \n",
      "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
      "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  importlib_metadata                       7.0.1-hd8ed1ab_0 --> 7.1.0-hd8ed1ab_0 \n",
      "  openssl                                  3.2.1-hd590300_0 --> 3.2.1-hd590300_1 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  c-blosc2                                2.13.2-hb4ffafa_0 --> 2.12.0-hb4ffafa_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "libopenvino-auto-plu | 232 KB    |                                       |   0% \n",
      "c-blosc2-2.12.0      | 326 KB    |                                       |   0% \u001b[A\n",
      "\n",
      "libopenvino-onnx-fro | 1.5 MB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pugixml-1.14         | 112 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "p11-kit-0.24.1       | 4.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 448 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "c-blosc2-2.12.0      | 326 KB    | #########                             |  25% \u001b[A\n",
      "\n",
      "libopenvino-onnx-fro | 1.5 MB    | 3                                     |   1% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-auto-plu | 232 KB    | ##5                                   |   7% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pugixml-1.14         | 112 KB    | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | 3                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    | ####4                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ###                                   |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ######3                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "c-blosc2-2.12.0      | 326 KB    | ##################################### | 100% \u001b[A\n",
      "c-blosc2-2.12.0      | 326 KB    | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##                                    |   5% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-auto-plu | 232 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "p11-kit-0.24.1       | 4.5 MB    | 1                                     |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | #####################3                |  58% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ###########4                          |  31% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ######                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pugixml-1.14         | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pugixml-1.14         | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "p11-kit-0.24.1       | 4.5 MB    | ###############                       |  41% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | #################7                    |  48% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ###3                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ###########7                          |  32% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ############3                         |  34% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "p11-kit-0.24.1       | 4.5 MB    | ##########################9           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libopenvino-paddle-f | 644 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ######################8               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | #####################7                |  59% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ###################2                  |  52% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    | 6                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | #############################         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ############################5         |  77% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | 5                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | #####2                                |  14% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ########################9             |  67% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 448 KB    | #3                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ###2                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ####################################  |  97% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ####################################7 |  99% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-ir-front | 194 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenvino-onnx-fro | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | #################################4    |  90% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libopenvino-onnx-fro | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    | ########3                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    | ##################6                   |  50% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libdrm-2.4.120       | 296 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libpciaccess-0.18    | 28 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    | ################################1     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "x264-1!164.3095      | 877 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-hetero-p | 177 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libvpx-1.13.1        | 982 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "gnutls-3.7.9         | 1.9 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-pytorch- | 937 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-auto-bat | 112 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "nettle-3.9.1         | 988 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 448 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-tensorfl | 448 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libva-2.21.0         | 185 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-gp | 7.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "libopenvino-intel-cp | 9.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ffmpeg-6.1.1         | 9.3 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "p11-kit-0.24.1       | 4.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "botocore-1.34.84     | 6.6 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "built with gcc 12.3.0 (conda-forge gcc 12.3.0-5)\n",
      "configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1706918361713/_build_env/bin/pkg-config\n",
      "libavutil      58. 29.100 / 58. 29.100\n",
      "libavcodec     60. 31.102 / 60. 31.102\n",
      "libavformat    60. 16.100 / 60. 16.100\n",
      "libavdevice    60.  3.100 / 60.  3.100\n",
      "libavfilter     9. 12.100 /  9. 12.100\n",
      "libswscale      7.  5.100 /  7.  5.100\n",
      "libswresample   4. 12.100 /  4. 12.100\n",
      "libpostproc    57.  3.100 / 57.  3.100\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ffmpeg -y\n",
    "!ffmpeg -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "def get_audio_duration(audio_file_path):\n",
    "    \"\"\"\n",
    "    Get the duration of an audio file.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_file_path (str): Path to the audio file.\n",
    "    \n",
    "    Returns:\n",
    "    - duration (float): Duration of the audio file in seconds.\n",
    "    \"\"\"\n",
    "    # Load the audio file clip\n",
    "    audio_clip = AudioFileClip(audio_file_path)\n",
    "    \n",
    "    # Get the duration of the audio clip\n",
    "    duration = audio_clip.duration\n",
    "    \n",
    "    # Close the audio clip\n",
    "    audio_clip.close()\n",
    "    \n",
    "    return duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration of the audio file: 60.94 seconds\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = \"converted_audios/Mod02_Intro.wav\"\n",
    "duration = get_audio_duration(audio_file_path)\n",
    "print(\"Duration of the audio file:\", duration, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to extract a segment of audio from whole audio file\n",
    "\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def extract_audio_segment(audio_file, start_time, end_time):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_file(audio_file)\n",
    "\n",
    "    # Extract the desired segment\n",
    "    audio_segment = audio[start_time * 1000:end_time * 1000]  # Convert time to milliseconds\n",
    "\n",
    "    return audio_segment\n",
    "\n",
    "# # Example usage: Extract audio segment from 10 to 20 seconds\n",
    "audio_file = \"converted_audios/Mod02_Sect02.wav\"\n",
    "start_time = 120 \n",
    "end_time = 300    \n",
    "audio_segment = extract_audio_segment(audio_file, start_time, end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "audio_directory = \"converted_audios\"\n",
    "output_directory = \"transcribed_texts\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def transcribe_all_files():\n",
    "    for audio_file in os.listdir(audio_directory):\n",
    "        audio_name = os.path.splitext(audio_file)[0]\n",
    "        output_text = os.path.join(output_directory, f\"{audio_name}.txt\")\n",
    "        transcribe_single_file(audio_file, output_text)\n",
    "\n",
    "def transcribe_single_file(audio_file, output_text):\n",
    "    duration = get_audio_duration(os.path.join(audio_directory, audio_file))\n",
    "    duration_used = math.floor(duration)\n",
    "    segment_duration = 120  # Duration of each segment in seconds\n",
    "\n",
    "    for start_duration in range(0, duration_used, segment_duration):\n",
    "        end_duration = min(start_duration + segment_duration, duration_used)\n",
    "        \n",
    "        audio_segment = extract_audio_segment(os.path.join(audio_directory, audio_file), start_duration, end_duration)\n",
    "        \n",
    "        output_file = f\"output_segment_{start_duration}-{end_duration}.wav\"\n",
    "        audio_segment.export(output_file, format=\"wav\")\n",
    "        \n",
    "        # Initialize recognizer \n",
    "        r = sr.Recognizer()\n",
    "\n",
    "        # Load the audio file \n",
    "        with sr.AudioFile(output_file) as source:\n",
    "            data = r.record(source)\n",
    "\n",
    "        # Perform speech recognition\n",
    "        text = r.recognize_google(data)\n",
    "        \n",
    "        # Write the transcription result to the text file\n",
    "        with open(output_text, 'a') as file:\n",
    "            file.write(' ' + text)\n",
    "            \n",
    "    return 'Transcription Success'\n",
    "\n",
    "transcribe_all_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "import os\n",
    "\n",
    "def read_text_files(directory_path):\n",
    "\n",
    "    text_list = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "    \n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                text_list.append(file.read())\n",
    "    return text_list\n",
    "\n",
    "directory_path = \"transcribed_texts\"  \n",
    "text_data = read_text_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lowercase_and_strip(text):\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    return text\n",
    "\n",
    "def replace_mentions_and_hashtags(text):\n",
    "    # Improved regex to handle usernames with underscores\n",
    "    text = re.sub(r'@[\\w_]+', '', text)\n",
    "    hashtags = re.findall(r'#(\\w+)', text)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def remove_links(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    return text\n",
    "\n",
    "def replace_punctuation_with_space(text):\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    text = re.compile('[^A-Za-z0-9@#]+').sub(' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in words if w.lower() not in stop_words]\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    return text\n",
    "\n",
    "def lemmatize_text(lemmatizer, text):\n",
    "    # lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(text)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    text = \" \".join(lemmatized_words)\n",
    "    return text\n",
    "\n",
    "def remove_numericals(text):\n",
    "    text = re.compile('[^A-Za-z]+').sub(' ', text)\n",
    "    return text\n",
    "def remove_short_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in words if len(w)>2]\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    return text    \n",
    "\n",
    "\n",
    "normalized_texts = []\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for text in text_data:\n",
    "    processed_text = lowercase_and_strip(text)\n",
    "    processed_text = remove_html_tags(processed_text)\n",
    "    processed_text = replace_mentions_and_hashtags(processed_text)\n",
    "    processed_text = remove_links(processed_text)\n",
    "    processed_text = remove_stopwords(processed_text)\n",
    "    processed_text = remove_special_characters(processed_text)\n",
    "    processed_text = remove_numericals(processed_text)\n",
    "    processed_text = replace_punctuation_with_space(processed_text)\n",
    "    \n",
    "    processed_text = lemmatize_text(lemmatizer, processed_text)\n",
    "    processed_text = remove_short_words(processed_text)\n",
    "    \n",
    "    normalized_texts.append(processed_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text preprocessing completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    processed_text = lowercase_and_strip(text)\n",
    "    processed_text = remove_html_tags(processed_text)\n",
    "    processed_text = replace_mentions_and_hashtags(processed_text)\n",
    "    processed_text = remove_links(processed_text)\n",
    "    processed_text = remove_stopwords(processed_text)\n",
    "    processed_text = remove_special_characters(processed_text)\n",
    "    processed_text = remove_numericals(processed_text)\n",
    "    processed_text = replace_punctuation_with_space(processed_text)\n",
    "    processed_text = lemmatize_text(lemmatizer, processed_text)\n",
    "    processed_text = remove_short_words(processed_text)\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "output_dir = \"preprocessed_texts\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for filename in os.listdir(\"transcribed_texts\"):\n",
    "    # Skip directories\n",
    "    if os.path.isdir(os.path.join(\"transcribed_texts\", filename)):\n",
    "        continue\n",
    "\n",
    "    input_file_path = os.path.join(\"transcribed_texts\", filename)\n",
    "    output_file_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    with open(input_file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    processed_text = preprocess_text(text)\n",
    "    \n",
    "    with open(output_file_path, \"w\") as file:\n",
    "        file.write(processed_text)\n",
    "\n",
    "print(\"Text preprocessing completed.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (1.12.0)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
      "Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.4\n"
     ]
    }
   ],
   "source": [
    "# Write your answer/code here\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yake\n",
      "  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tabulate in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: click>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yake) (8.1.7)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yake) (1.22.4)\n",
      "Collecting segtok (from yake)\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yake) (3.2.1)\n",
      "Requirement already satisfied: jellyfish in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yake) (1.0.3)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from segtok->yake) (2023.12.25)\n",
      "Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m702.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: segtok, yake\n",
      "Successfully installed segtok-1.5.11 yake-0.4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Phrases for Text 1:\n",
      "- time series data\n",
      "- working time series\n",
      "- series data list\n",
      "- challenge working time\n",
      "- aws academy machine\n",
      "- academy machine learning\n",
      "- business problem solved\n",
      "- list step required\n",
      "- step required create\n",
      "- problem solved amazon\n",
      "- data list step\n",
      "- forecasting start introduction\n",
      "- start introduction forecasting\n",
      "- describe business problem\n",
      "- describe challenge working\n",
      "- module aws academy\n",
      "- machine learning module\n",
      "- simplify building forecast\n",
      "- building forecast end\n",
      "- required create forecast\n",
      "\n",
      "Key Phrases for Text 2:\n",
      "- feature data set\n",
      "- data set information\n",
      "- data set made\n",
      "- scatter plot matrix\n",
      "- data set imbalance\n",
      "- imbalance data set\n",
      "- set imbalance data\n",
      "- relationship scatter plot\n",
      "- plot box plot\n",
      "- set information give\n",
      "- column data set\n",
      "- set made credit\n",
      "- variable scatter plot\n",
      "- set information relates\n",
      "- instance data set\n",
      "- scatter plot good\n",
      "- car data set\n",
      "- numerical variable feature\n",
      "- descriptive statistic data\n",
      "- create scatter plot\n",
      "\n",
      "Key Phrases for Text 3:\n",
      "- distributed training job\n",
      "- sagemaker hyperparameter tuning\n",
      "- metric training job\n",
      "- training job performs\n",
      "- result training job\n",
      "- training tuning machine\n",
      "- training job data\n",
      "- training job time\n",
      "- tuning job improves\n",
      "- process training tuning\n",
      "- objective metric training\n",
      "- multiple training job\n",
      "- instance training job\n",
      "- hyperparameter tuning job\n",
      "- launch training job\n",
      "- return training job\n",
      "- training job highest\n",
      "- training job run\n",
      "- training job design\n",
      "- training job report\n",
      "\n",
      "Key Phrases for Text 4:\n",
      "- amazon recognition custom\n",
      "- recognition custom label\n",
      "- train amazon recognition\n",
      "- machine learning process\n",
      "- learning amazon recognition\n",
      "- training data set\n",
      "- amazon recognition\n",
      "- training computer vision\n",
      "- amazon recognition detect\n",
      "- amazon recognition trained\n",
      "- model amazon recognition\n",
      "- card amazon recognition\n",
      "- labeled amazon recognition\n",
      "- includes amazon recognition\n",
      "- amazon recognition recognizes\n",
      "- capability amazon recognition\n",
      "- trained ten million\n",
      "- amazon recognition result\n",
      "- amazon recognition encounter\n",
      "- amazon recognition step\n",
      "\n",
      "Key Phrases for Text 5:\n",
      "- business problem solved\n",
      "- series data list\n",
      "- data list step\n",
      "- list step required\n",
      "- step required create\n",
      "- problem solved amazon\n",
      "- back time review\n",
      "- review module wrap\n",
      "- wrap module learned\n",
      "- learned describe business\n",
      "- describe business problem\n",
      "- describe challenge working\n",
      "- challenge working time\n",
      "- working time series\n",
      "- time series data\n",
      "- required create forecast\n",
      "- forecast make prediction\n",
      "- amazon forecast make\n",
      "- solved amazon forecast\n",
      "- time review module\n",
      "\n",
      "Key Phrases for Text 6:\n",
      "- case amazon comprehend\n",
      "- amazon translate create\n",
      "- amazon comprehend amazon\n",
      "- amazon polly convert\n",
      "- case amazon polly\n",
      "- case amazon translate\n",
      "- amazon transcribe capture\n",
      "- case amazon transcribe\n",
      "- application amazon translate\n",
      "- language amazon translate\n",
      "- language amazon comprehend\n",
      "- service amazon comprehend\n",
      "- amazon polly create\n",
      "- amazon comprehend create\n",
      "- case amazon lexus\n",
      "- application amazon alexa\n",
      "- language amazon alexa\n",
      "- content amazon comprehend\n",
      "- service application amazon\n",
      "- amazon alexa create\n",
      "\n",
      "Key Phrases for Text 7:\n",
      "- wrap knowledge check\n",
      "- learned formulate problem\n",
      "- formulate problem business\n",
      "- problem business request\n",
      "- business request obtain\n",
      "- request obtain secure\n",
      "- build jupyter notebook\n",
      "- open source tool\n",
      "- source tool examine\n",
      "- cross validation test\n",
      "- validation test performance\n",
      "- perimeter tuning job\n",
      "- tuning job optimize\n",
      "- train host machine\n",
      "- learning build jupyter\n",
      "- machine learning build\n",
      "- host machine learning\n",
      "- sagemaker train host\n",
      "- inference create amazon\n",
      "- sagemaker perimeter tuning\n",
      "\n",
      "Key Phrases for Text 8:\n",
      "- time series data\n",
      "- finally grain time\n",
      "- time time series\n",
      "- missing sale data\n",
      "- series data data\n",
      "- situation demand forecasting\n",
      "- retail missing sale\n",
      "- time series specific\n",
      "- calculate missing data\n",
      "- missing data case\n",
      "- marked missing missing\n",
      "- point time time\n",
      "- series data suppose\n",
      "- stock situation demand\n",
      "- processing time series\n",
      "- addition time series\n",
      "- extrapolate time series\n",
      "- irregular time series\n",
      "- true time series\n",
      "- time series depending\n",
      "\n",
      "Key Phrases for Text 9:\n",
      "- part artificial intelligence\n",
      "- solve business problem\n",
      "- business problem solved\n",
      "- artificial intelligence machine\n",
      "- challenge face completing\n",
      "- traditional software development\n",
      "- software development method\n",
      "- development method ready\n",
      "- problem solved machine\n",
      "- learning part artificial\n",
      "- aws academy machine\n",
      "- deep learning part\n",
      "- artificial intelligence describe\n",
      "- intelligence describe artificial\n",
      "- describe artificial intelligence\n",
      "- business problem describe\n",
      "- intelligence machine learning\n",
      "- academy machine learning\n",
      "- introduce machine learning\n",
      "- solved machine learning\n",
      "\n",
      "Key Phrases for Text 10:\n",
      "- time series data\n",
      "- opportunity predicting future\n",
      "- component add additional\n",
      "- year month day\n",
      "- series data falling\n",
      "- area machine learning\n",
      "- predicting future outcome\n",
      "- future outcome based\n",
      "- outcome based historical\n",
      "- add additional information\n",
      "- problem difficult handle\n",
      "- difficult handle compared\n",
      "- increasing decreasing staying\n",
      "- important area machine\n",
      "- machine learning important\n",
      "- handle compared type\n",
      "- compared type prediction\n",
      "- large retail sale\n",
      "- retail sale event\n",
      "- management system anticipate\n",
      "\n",
      "Key Phrases for Text 11:\n",
      "- obtain data multiple\n",
      "- access resource make\n",
      "- make easy obtain\n",
      "- history play account\n",
      "- retain account activity\n",
      "- account activity related\n",
      "- play account activity\n",
      "- account activity including\n",
      "- secure transport layer\n",
      "- store finally make\n",
      "- event history play\n",
      "- event history simplifies\n",
      "- solving machine learning\n",
      "- machine learning problem\n",
      "- train machine learning\n",
      "- machine learning model\n",
      "- service event history\n",
      "- activity aws account\n",
      "- account cloudtrail log\n",
      "- monitor retain account\n",
      "\n",
      "Key Phrases for Text 12:\n",
      "- amazon recognition video\n",
      "- recognition video stream\n",
      "- application amazon recognition\n",
      "- amazon recognition\n",
      "- streaming amazon recognition\n",
      "- stream amazon recognition\n",
      "- recognition video amazon\n",
      "- video amazon recognition\n",
      "- collection amazon recognition\n",
      "- recognition video streaming\n",
      "- amazon recognition detects\n",
      "- amazon recognition process\n",
      "- result amazon recognition\n",
      "- bounding box coordinate\n",
      "- amazon recognition perform\n",
      "- prediction amazon recognition\n",
      "- amazon recognition summary\n",
      "- output amazon recognition\n",
      "- summary amazon recognition\n",
      "- amazon recognition compare\n",
      "\n",
      "Key Phrases for Text 13:\n",
      "- machine learning problem\n",
      "- challenge machine learning\n",
      "- machine learning\n",
      "- machine learning lot\n",
      "- formulating machine learning\n",
      "- operating machine learning\n",
      "- substantial machine learning\n",
      "- machine learning knowledge\n",
      "- machine learning add\n",
      "- sophisticated machine learning\n",
      "- machine learning capability\n",
      "- service machine learning\n",
      "- machine learning challenge\n",
      "- machine learning solution\n",
      "- solve machine learning\n",
      "- machine learning business\n",
      "- managed service machine\n",
      "- learning lot poor\n",
      "- complex formulating machine\n",
      "- updating operating machine\n",
      "\n",
      "Key Phrases for Text 14:\n",
      "- amazon recognition custom\n",
      "- recognition custom label\n",
      "- detect custom label\n",
      "- custom label operation\n",
      "- returned detect custom\n",
      "- custom label returned\n",
      "- custom label includes\n",
      "- model calculated threshold\n",
      "- object custom label\n",
      "- training data set\n",
      "- concept found image\n",
      "- custom label\n",
      "- default detect custom\n",
      "- custom label accuracy\n",
      "- number custom label\n",
      "- returned array custom\n",
      "- array custom label\n",
      "- finally custom label\n",
      "- set custom labeling\n",
      "- custom label represents\n",
      "\n",
      "Key Phrases for Text 15:\n",
      "- amazon sagemaker algorithm\n",
      "- amazon sagemaker provides\n",
      "- amazon sagemaker includes\n",
      "- problem amazon sagemaker\n",
      "- model amazon sagemaker\n",
      "- sagemaker amazon sagemaker\n",
      "- amazon sagemaker amazon\n",
      "- amazon sagemaker\n",
      "- learning amazon sagemaker\n",
      "- format amazon sagemaker\n",
      "- test data set\n",
      "- amazon sagemaker train\n",
      "- built amazon sagemaker\n",
      "- amazon sagemaker container\n",
      "- directly amazon sagemaker\n",
      "- column amazon sagemaker\n",
      "- amazon sagemaker sdk\n",
      "- amazon sagemaker linear\n",
      "- objective amazon sagemaker\n",
      "- careful cross validation\n",
      "\n",
      "Key Phrases for Text 16:\n",
      "- natural language processing\n",
      "- managed amazon service\n",
      "- introduction natural language\n",
      "- introduce natural language\n",
      "- amazon service describe\n",
      "- describe managed amazon\n",
      "- learning introduction natural\n",
      "- aws academy machine\n",
      "- academy machine learning\n",
      "- machine learning introduction\n",
      "- section includes description\n",
      "- includes description major\n",
      "- description major challenge\n",
      "- major challenge faced\n",
      "- review ava speed\n",
      "- language processing module\n",
      "- service describe managed\n",
      "- application review ava\n",
      "- ava speed development\n",
      "- based application completing\n",
      "\n",
      "Key Phrases for Text 17:\n",
      "- prepare custom data\n",
      "- custom data set\n",
      "- time summarize main\n",
      "- required prepare custom\n",
      "- data set object\n",
      "- summarize main point\n",
      "- management learning service\n",
      "- analysis list step\n",
      "- list step required\n",
      "- sagemaker ground truth\n",
      "- recognition perform facial\n",
      "- step required prepare\n",
      "- concludes introduction computer\n",
      "- case computer vision\n",
      "- introduction computer vision\n",
      "- main point module\n",
      "- image video analysis\n",
      "- video analysis list\n",
      "- perform facial detection\n",
      "- facial detection concludes\n",
      "\n",
      "Key Phrases for Text 18:\n",
      "- total number actual\n",
      "- cat correctly identified\n",
      "- correctly identified cat\n",
      "- divide total number\n",
      "- choose wanted make\n",
      "- number actual cat\n",
      "- positive identification cat\n",
      "- correctly identified divided\n",
      "- work correctly identified\n",
      "- correctly identified calculate\n",
      "- negative correctly identified\n",
      "- identified divided total\n",
      "- number cat correctly\n",
      "- number positive identification\n",
      "- number true positive\n",
      "- true positive number\n",
      "- number actual negative\n",
      "- number true negative\n",
      "- positive number positive\n",
      "- image cat correctly\n",
      "\n",
      "Key Phrases for Text 19:\n",
      "- data multiple column\n",
      "- ordinary multiple column\n",
      "- machine learning model\n",
      "- section machine learning\n",
      "- improve machine learning\n",
      "- specific machine learning\n",
      "- machine learning algorithm\n",
      "- make model successful\n",
      "- text column numerical\n",
      "- multiple column feature\n",
      "- capture ordinal relationship\n",
      "- introduce ordinal relationship\n",
      "- thing improve machine\n",
      "- selection prevent redundancy\n",
      "- task section machine\n",
      "- selection select relevant\n",
      "- altogether specific machine\n",
      "- learning algorithm work\n",
      "- encode text numerical\n",
      "- dealing missing numerical\n",
      "\n",
      "Key Phrases for Text 20:\n",
      "- multi model endpoint\n",
      "- deploy model amazon\n",
      "- prediction entire data\n",
      "- deploy train model\n",
      "- host multiple model\n",
      "- model create endpoint\n",
      "- entire data set\n",
      "- data processing step\n",
      "- prediction deploy model\n",
      "- model amazon sagemaker\n",
      "- endpoint make prediction\n",
      "- single prediction deploy\n",
      "- inference prediction model\n",
      "- instance deploy model\n",
      "- deploy model set\n",
      "- make prediction model\n",
      "- make inference prediction\n",
      "- deploy model single\n",
      "- create endpoint model\n",
      "- model endpoint multi\n",
      "\n",
      "Key Phrases for Text 21:\n",
      "- model training data\n",
      "- training data model\n",
      "- overfitting training data\n",
      "- time train model\n",
      "- model training model\n",
      "- train model training\n",
      "- age birth month\n",
      "- training data perform\n",
      "- model overfitting training\n",
      "- training model evaluation\n",
      "- feature engineering training\n",
      "- result training model\n",
      "- training evaluating model\n",
      "- processing model training\n",
      "- training data evaluation\n",
      "- data train model\n",
      "- training model real\n",
      "- model data feature\n",
      "- train model process\n",
      "- data model performs\n",
      "\n",
      "Key Phrases for Text 22:\n",
      "- system convert text\n",
      "- convert text data\n",
      "- human machine interaction\n",
      "- task nlp application\n",
      "- form word run\n",
      "- natural language processing\n",
      "- system machine learning\n",
      "- inverse document frequency\n",
      "- number time word\n",
      "- form machine learning\n",
      "- machine learning nlp\n",
      "- nlp system machine\n",
      "- machine learning algorithm\n",
      "- apply machine learning\n",
      "- feature machine learning\n",
      "- predate machine learning\n",
      "- system predate machine\n",
      "- machine learning large\n",
      "- machine learning drive\n",
      "- data system convert\n",
      "\n",
      "Key Phrases for Text 23:\n",
      "- great topic today\n",
      "- explore detail analyzing\n",
      "- analysis list step\n",
      "- list step required\n",
      "- sagemaker ground truth\n",
      "- recognition perform facial\n",
      "- detail analyzing image\n",
      "- academy machine learning\n",
      "- customized data set\n",
      "- data set performing\n",
      "- set performing object\n",
      "- management machine learning\n",
      "- custom data set\n",
      "- topic today computer\n",
      "- start overview computer\n",
      "- vision space learn\n",
      "- data set object\n",
      "- today computer vision\n",
      "- overview computer vision\n",
      "- computer vision space\n",
      "\n",
      "Key Phrases for Text 24:\n",
      "- machine learning model\n",
      "- machine learning pipeline\n",
      "- data machine learning\n",
      "- machine learning problem\n",
      "- credit card transaction\n",
      "- reduction number customer\n",
      "- machine learning\n",
      "- make prediction section\n",
      "- machine learning make\n",
      "- reminder machine learning\n",
      "- requirement machine learning\n",
      "- solved machine learning\n",
      "- unsupervised machine learning\n",
      "- term machine learning\n",
      "- irvine machine learning\n",
      "- processed machine learning\n",
      "- machine learning activity\n",
      "- machine learning traditional\n",
      "- machine learning purpose\n",
      "- machine learning repository\n",
      "\n",
      "Key Phrases for Text 25:\n",
      "- time series data\n",
      "- series data set\n",
      "- include time series\n",
      "- wrangling time series\n",
      "- random time series\n",
      "- face time series\n",
      "- independent time series\n",
      "- time series refer\n",
      "- excellent time series\n",
      "- handling time series\n",
      "- information time series\n",
      "- time series support\n",
      "- set amazon forecast\n",
      "- trend time series\n",
      "- series refer documentation\n",
      "- series support function\n",
      "- series trend difficult\n",
      "- series data sequence\n",
      "- data set amazon\n",
      "- time series autocorrelation\n",
      "\n",
      "Key Phrases for Text 26:\n",
      "- source data set\n",
      "- run training job\n",
      "- target answer prediction\n",
      "- data machine learning\n",
      "- credit card fraud\n",
      "- open source data\n",
      "- predict credit card\n",
      "- training job amazon\n",
      "- relational database service\n",
      "- training data amazon\n",
      "- data source training\n",
      "- source training data\n",
      "- training data set\n",
      "- intended business outcome\n",
      "- source target fraud\n",
      "- database service amazon\n",
      "- desired output subsequently\n",
      "- credit card transaction\n",
      "- target fraud fraud\n",
      "- job amazon sagemaker\n",
      "\n",
      "Key Phrases for Text 27:\n",
      "- artificial intelligence machine\n",
      "- part artificial intelligence\n",
      "- stage developing machine\n",
      "- discussing challenge machine\n",
      "- learned recognize machine\n",
      "- intelligence machine learning\n",
      "- intelligence describe artificial\n",
      "- describe artificial intelligence\n",
      "- artificial intelligence describe\n",
      "- machine learning\n",
      "- type problem machine\n",
      "- terminology identify machine\n",
      "- defining machine learning\n",
      "- machine learning fit\n",
      "- machine learning applies\n",
      "- machine learning pipeline\n",
      "- developing machine learning\n",
      "- machine learning application\n",
      "- challenge machine learning\n",
      "- machine learning summary\n",
      "\n",
      "Key Phrases for Text 28:\n",
      "- machine learning program\n",
      "- reinforcement learning model\n",
      "- learning supervised learning\n",
      "- learning reinforcement learning\n",
      "- learning program trained\n",
      "- machine learning supervised\n",
      "- machine learning reinforcement\n",
      "- problem machine learning\n",
      "- machine learning problem\n",
      "- unsupervised machine learning\n",
      "- machine learning\n",
      "- problem supervised learning\n",
      "- supervised learning problem\n",
      "- type machine learning\n",
      "- learn desired driving\n",
      "- fraud machine learning\n",
      "- variable machine learning\n",
      "- machine learning application\n",
      "- data reinforcement learning\n",
      "- type supervised learning\n",
      "\n",
      "Key Phrases for Text 29:\n",
      "- clean data set\n",
      "- data set missing\n",
      "- set missing data\n",
      "- variable describes number\n",
      "- missing data make\n",
      "- drop impute missing\n",
      "- missing data data\n",
      "- row missing data\n",
      "- missing data drop\n",
      "- missing data decide\n",
      "- missing data variable\n",
      "- drop row missing\n",
      "- road missing data\n",
      "- underway missing data\n",
      "- finding missing data\n",
      "- role missing data\n",
      "- find data missing\n",
      "- data set includes\n",
      "- column data set\n",
      "- drop road missing\n",
      "\n",
      "Key Phrases for Text 30:\n",
      "- machine learning framework\n",
      "- open source machine\n",
      "- lab open source\n",
      "- machine learning\n",
      "- source machine learning\n",
      "- notebook open source\n",
      "- open source web\n",
      "- open source python\n",
      "- computing machine learning\n",
      "- jupiter lab open\n",
      "- learn open source\n",
      "- number open source\n",
      "- jupyter notebook open\n",
      "- machine learning jupiter\n",
      "- scientific computing machine\n",
      "- machine learning borrow\n",
      "- tuned machine learning\n",
      "- machine learning cloud\n",
      "- party machine learning\n",
      "- machine learning developer\n",
      "\n",
      "Key Phrases for Text 31:\n",
      "- box plot show\n",
      "- feature selection method\n",
      "- selection start feature\n",
      "- feature training model\n",
      "- plot box plot\n",
      "- method embedded method\n",
      "- method filter method\n",
      "- selection method filter\n",
      "- box plot box\n",
      "- method involve training\n",
      "- rapper filter method\n",
      "- filter rapper method\n",
      "- rapper method measure\n",
      "- selection method popular\n",
      "- variable box plot\n",
      "- variable rapper method\n",
      "- category pre processing\n",
      "- deal pre processing\n",
      "- pre processing phase\n",
      "- pre processing step\n",
      "\n",
      "Key Phrases for Text 32:\n",
      "- amazon recognition custom\n",
      "- recognition custom label\n",
      "- test data set\n",
      "- entire test data\n",
      "- custom label return\n",
      "- custom label test\n",
      "- image test data\n",
      "- metric entire test\n",
      "- presence custom label\n",
      "- custom label present\n",
      "- return cat label\n",
      "- create test data\n",
      "- label test image\n",
      "- predicts presence custom\n",
      "- truth label image\n",
      "- label ground truth\n",
      "- ground truth label\n",
      "- training data set\n",
      "- test image predicted\n",
      "- image predicted label\n",
      "\n",
      "Key Phrases for Text 33:\n",
      "- time series data\n",
      "- quantile predicts time\n",
      "- predicts time true\n",
      "- time fewer pair\n",
      "- fewer pair sold\n",
      "- amazon forecast create\n",
      "- amazon forecast train\n",
      "- sold time fewer\n",
      "- pair sold time\n",
      "- weighted quantile loss\n",
      "- demand winter glove\n",
      "- forecast create predictor\n",
      "- model make forecast\n",
      "- model forecast reliable\n",
      "- domain specific type\n",
      "- input data set\n",
      "- back test window\n",
      "- data set group\n",
      "- cost invested capital\n",
      "- specific type data\n",
      "\n",
      "Key Phrases for Text 34:\n",
      "- machine learning pipeline\n",
      "- machine learning section\n",
      "- machine learning\n",
      "- machine learning problem\n",
      "- certified machine learning\n",
      "- statistic machine learning\n",
      "- implement machine learning\n",
      "- machine learning specialty\n",
      "- machine learning engineer\n",
      "- amazon machine learning\n",
      "- natural language processing\n",
      "- machine learning service\n",
      "- machine learning model\n",
      "- learning section describes\n",
      "- learning machine learning\n",
      "- field machine learning\n",
      "- machine learning technology\n",
      "- machine learning professional\n",
      "- aws certified machine\n",
      "- learning specialty section\n",
      "\n",
      "Key Phrases for Text 35:\n",
      "- machine learning model\n",
      "- machine learning pipeline\n",
      "- machine learning problem\n",
      "- amazon sagemaker outline\n",
      "- amazon sagemaker train\n",
      "- learning pipeline applied\n",
      "- academy machine learning\n",
      "- entire machine learning\n",
      "- handling machine learning\n",
      "- type machine learning\n",
      "- machine learning build\n",
      "- host machine learning\n",
      "- performance machine learning\n",
      "- focus supervised learning\n",
      "- learning build jupyter\n",
      "- inference full stop\n",
      "- learning problem machine\n",
      "- problem machine learning\n",
      "- learning problem focus\n",
      "- sagemaker train host\n",
      "\n",
      "Key Phrases for Text 36:\n",
      "- amazon recognition analyzes\n",
      "- result amazon recognition\n",
      "- recognition analyzes image\n",
      "- amazon recognition\n",
      "- recognition amazon recognition\n",
      "- image inappropriate content\n",
      "- amazon recognition amazon\n",
      "- image stored video\n",
      "- amazon recognition performs\n",
      "- video amazon recognition\n",
      "- call amazon recognition\n",
      "- service amazon recognition\n",
      "- detected object image\n",
      "- amazon recognition apis\n",
      "- sdk amazon recognition\n",
      "- amazon recognition sdk\n",
      "- image amazon recognition\n",
      "- data amazon recognition\n",
      "- finally amazon recognition\n",
      "- amazon recognition build\n",
      "\n",
      "Key Phrases for Text 37:\n",
      "- case computer vision\n",
      "- computer vision automated\n",
      "- computer vision technology\n",
      "- vision automated extraction\n",
      "- vision computer vision\n",
      "- computer vision computer\n",
      "- computer vision\n",
      "- automated extraction information\n",
      "- technology computer vision\n",
      "- vision technology computer\n",
      "- analysis computer vision\n",
      "- trained computer vision\n",
      "- computer vision problem\n",
      "- computer vision improve\n",
      "- computer vision video\n",
      "- computer vision machine\n",
      "- efficiency computer vision\n",
      "- computer vision exciting\n",
      "- computer vision incorporated\n",
      "- computer vision covering\n",
      "\n",
      "Key Phrases for Text 38:\n",
      "- aws glue data\n",
      "- glue data catalog\n",
      "- catalog aws glue\n",
      "- aws glue\n",
      "- extract transform load\n",
      "- set aws glue\n",
      "- store aws glue\n",
      "- aws glue service\n",
      "- aws glue run\n",
      "- aws glue console\n",
      "- aws glue training\n",
      "- table aws glue\n",
      "- process aws glue\n",
      "- aws glue fully\n",
      "- aws glue consists\n",
      "- retries aws glue\n",
      "- aws glue serverless\n",
      "- aws glue api\n",
      "- interface aws glue\n",
      "- environment aws glue\n",
      "\n",
      "Key Phrases for Text 39:\n",
      "- quantify linear relationship\n",
      "- weak linear relationship\n",
      "- linear relationship quantified\n",
      "- relationship indication linear\n",
      "- indication linear relationship\n",
      "- minus linear relationship\n",
      "- set quantify linear\n",
      "- proportional minus linear\n",
      "- strong weak linear\n",
      "- seaborne heat map\n",
      "- heat map highest\n",
      "- heat map function\n",
      "- matrix good tool\n",
      "- map function show\n",
      "- citric acid contributes\n",
      "- expected citric acid\n",
      "- back review find\n",
      "- good tool situation\n",
      "- tool situation conveys\n",
      "- situation conveys strong\n",
      "\n",
      "Key Phrases for Text 40:\n",
      "- sagemaker ground truth\n",
      "- automated data labeling\n",
      "- amazon recognition custom\n",
      "- recognition custom label\n",
      "- label data set\n",
      "- data set data\n",
      "- labeling sagemaker ground\n",
      "- training data set\n",
      "- human label data\n",
      "- set data set\n",
      "- custom label model\n",
      "- amazon sagemaker ground\n",
      "- sends human worker\n",
      "- data set machine\n",
      "- data set\n",
      "- worker sagemaker ground\n",
      "- set data confidence\n",
      "- score data set\n",
      "- ground truth train\n",
      "- label sagemaker ground\n",
      "\n",
      "Key Phrases for Text 41:\n",
      "- false positive rate\n",
      "- positive false positive\n",
      "- difference prediction actual\n",
      "- positive rate false\n",
      "- rate false positive\n",
      "- true positive rate\n",
      "- email message spam\n",
      "- sensitivity true positive\n",
      "- calculate false positive\n",
      "- false positive high\n",
      "- positive rate graph\n",
      "- positive rate point\n",
      "- identify true positive\n",
      "- equal false positive\n",
      "- represents positive false\n",
      "- low false positive\n",
      "- false positive cost\n",
      "- positive cost false\n",
      "- cost false positive\n",
      "- true positive ideal\n",
      "\n",
      "Key Phrases for Text 42:\n",
      "- back time review\n",
      "- nlp good job\n",
      "- time review module\n",
      "- wrap summary module\n",
      "- review module wrap\n",
      "- module wrap summary\n",
      "- summary module learn\n",
      "- learn describe nlp\n",
      "- managed amazon service\n",
      "- amazon service describe\n",
      "- module learn describe\n",
      "- service describe managed\n",
      "- describe managed service\n",
      "- back time\n",
      "- time review\n",
      "- wrap summary\n",
      "- case solved\n",
      "- good job\n",
      "- job thanks watching\n",
      "- learn describe\n",
      "\n",
      "Key Phrases for Text 43:\n",
      "- predicted label class\n",
      "- cat predicted class\n",
      "- class actual label\n",
      "- actual label class\n",
      "- label class cat\n",
      "- good outcome model\n",
      "- similarly actual label\n",
      "- label cat identified\n",
      "- comparison predicted class\n",
      "- predicted class matched\n",
      "- class matched actual\n",
      "- matched actual class\n",
      "- happen actual class\n",
      "- choose face linked\n",
      "- class cat identified\n",
      "- reason hold sample\n",
      "- performed confusion matrix\n",
      "- determine good job\n",
      "- outcome considered good\n",
      "- considered good outcome\n",
      "\n",
      "Key Phrases for Text 44:\n",
      "- certified machine learning\n",
      "- machine learning specialty\n",
      "- aws certified machine\n",
      "- academy machine learning\n",
      "- machine learning solution\n",
      "- implement machine learning\n",
      "- aws academy machine\n",
      "- completing aws academy\n",
      "- congratulation completing aws\n",
      "- machine learning\n",
      "- machine learning deep\n",
      "- describe machine learning\n",
      "- machine learning pipeline\n",
      "- amazon machine learning\n",
      "- machine learning approach\n",
      "- secure machine learning\n",
      "- working machine learning\n",
      "- machine learning implement\n",
      "- learning implement machine\n",
      "- machine learning service\n",
      "\n",
      "Key Phrases for Text 45:\n",
      "- machine learning subset\n",
      "- learning practitioner spend\n",
      "- building machine perform\n",
      "- artificial intelligence broad\n",
      "- machine deep learning\n",
      "- layer artificial neuron\n",
      "- intelligence machine learning\n",
      "- machine learning\n",
      "- algorithm statistical model\n",
      "- deep learning practitioner\n",
      "- machine learning practitioner\n",
      "- deep learning problem\n",
      "- machine learning model\n",
      "- artificial intelligence machine\n",
      "- learning subset artificial\n",
      "- deep learning started\n",
      "- spam deep learning\n",
      "- theory deep learning\n",
      "- prediction deep learning\n",
      "- machine learning understand\n",
      "\n",
      "Key Phrases for Text 46:\n",
      "- correct data type\n",
      "- data frame row\n",
      "- visualize analyze data\n",
      "- frame row label\n",
      "- column data frame\n",
      "- load data frame\n",
      "- row column column\n",
      "- row label column\n",
      "- row column format\n",
      "- type load data\n",
      "- label column label\n",
      "- documentation data frame\n",
      "- spreadsheet data frame\n",
      "- data frame describes\n",
      "- data frame series\n",
      "- data format type\n",
      "- data csv format\n",
      "- column column data\n",
      "- property data frame\n",
      "- data csv file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "\n",
    "def extract_key_phrases_from_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    language = \"en\"\n",
    "    max_ngram_size = 3\n",
    "    deduplication_threshold = 0.9\n",
    "    deduplication_algo = 'seqm'\n",
    "    window_size = 1\n",
    "    num_keywords = 20\n",
    "\n",
    "   \n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                dedupFunc=deduplication_algo, windowsSize=window_size, top=num_keywords, features=None)\n",
    "\n",
    "    \n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "\n",
    "    key_phrases = [keyphrase for keyphrase, _ in keywords]\n",
    "\n",
    "    return key_phrases\n",
    "\n",
    "preprocessed_texts_dir = \"preprocessed_texts\"\n",
    "\n",
    "key_phrases_list = []\n",
    "for file_name in os.listdir(preprocessed_texts_dir):\n",
    "    file_path = os.path.join(preprocessed_texts_dir, file_name)\n",
    "    if os.path.isfile(file_path):\n",
    "        key_phrases = extract_key_phrases_from_file(file_path)\n",
    "        key_phrases_list.append(key_phrases)\n",
    "\n",
    "# Print the key phrases\n",
    "for i, key_phrases in enumerate(key_phrases_list, start=1):\n",
    "    print(f\"Key Phrases for Text {i}:\")\n",
    "    for phrase in key_phrases:\n",
    "        print(\"-\", phrase)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "(0, '0.038*\"model\" + 0.031*\"label\" + 0.022*\"image\" + 0.020*\"recognition\" + 0.019*\"data\" + 0.013*\"amazon\" + 0.013*\"test\" + 0.012*\"set\" + 0.012*\"custom\" + 0.011*\"metric\"')\n",
      "\n",
      "Topic 2:\n",
      "(1, '0.051*\"data\" + 0.018*\"model\" + 0.012*\"use\" + 0.011*\"example\" + 0.011*\"value\" + 0.011*\"amazon\" + 0.010*\"feature\" + 0.009*\"set\" + 0.009*\"also\" + 0.008*\"need\"')\n",
      "\n",
      "Topic 3:\n",
      "(2, '0.026*\"amazon\" + 0.018*\"video\" + 0.017*\"image\" + 0.015*\"recognition\" + 0.014*\"use\" + 0.014*\"service\" + 0.009*\"detection\" + 0.009*\"object\" + 0.007*\"computer\" + 0.007*\"vision\"')\n",
      "\n",
      "Topic 4:\n",
      "(3, '0.020*\"learning\" + 0.020*\"data\" + 0.013*\"machine\" + 0.011*\"problem\" + 0.009*\"amazon\" + 0.009*\"example\" + 0.007*\"model\" + 0.007*\"time\" + 0.007*\"forecast\" + 0.007*\"use\"')\n",
      "\n",
      "Topic 5:\n",
      "(4, '0.031*\"machine\" + 0.029*\"learning\" + 0.015*\"data\" + 0.013*\"section\" + 0.012*\"model\" + 0.011*\"problem\" + 0.008*\"set\" + 0.008*\"computer\" + 0.007*\"module\" + 0.007*\"image\"')\n",
      "\n",
      "Topic 6:\n",
      "(5, '0.028*\"learning\" + 0.025*\"data\" + 0.022*\"machine\" + 0.017*\"amazon\" + 0.017*\"use\" + 0.011*\"module\" + 0.011*\"model\" + 0.009*\"aws\" + 0.009*\"nlp\" + 0.009*\"set\"')\n",
      "\n",
      "Topic 7:\n",
      "(6, '0.023*\"data\" + 0.018*\"correlation\" + 0.012*\"relationship\" + 0.011*\"use\" + 0.010*\"model\" + 0.009*\"mean\" + 0.009*\"feature\" + 0.008*\"two\" + 0.008*\"video\" + 0.008*\"value\"')\n",
      "\n",
      "Topic 8:\n",
      "(7, '0.016*\"data\" + 0.016*\"module\" + 0.015*\"model\" + 0.014*\"use\" + 0.013*\"service\" + 0.011*\"job\" + 0.011*\"amazon\" + 0.011*\"nlp\" + 0.010*\"hyperparameters\" + 0.010*\"managed\"')\n",
      "\n",
      "Topic 9:\n",
      "(8, '0.007*\"video\" + 0.006*\"data\" + 0.006*\"label\" + 0.005*\"amazon\" + 0.005*\"word\" + 0.005*\"image\" + 0.004*\"nlp\" + 0.004*\"text\" + 0.004*\"model\" + 0.004*\"recognition\"')\n",
      "\n",
      "Topic 10:\n",
      "(9, '0.033*\"model\" + 0.023*\"data\" + 0.015*\"amazon\" + 0.014*\"training\" + 0.013*\"use\" + 0.010*\"sagemaker\" + 0.009*\"feature\" + 0.008*\"algorithm\" + 0.007*\"learning\" + 0.007*\"value\"')\n",
      "\n",
      "Topic 11:\n",
      "(10, '0.068*\"data\" + 0.016*\"value\" + 0.013*\"model\" + 0.012*\"use\" + 0.011*\"also\" + 0.010*\"set\" + 0.009*\"learning\" + 0.009*\"training\" + 0.008*\"problem\" + 0.008*\"example\"')\n",
      "\n",
      "Topic 12:\n",
      "(11, '0.030*\"image\" + 0.029*\"data\" + 0.021*\"model\" + 0.020*\"label\" + 0.015*\"use\" + 0.012*\"computer\" + 0.012*\"vision\" + 0.011*\"amazon\" + 0.010*\"object\" + 0.010*\"set\"')\n",
      "\n",
      "Topic 13:\n",
      "(12, '0.020*\"image\" + 0.020*\"learning\" + 0.016*\"data\" + 0.016*\"amazon\" + 0.016*\"use\" + 0.013*\"machine\" + 0.013*\"time\" + 0.010*\"also\" + 0.010*\"recognition\" + 0.010*\"object\"')\n",
      "\n",
      "Topic 14:\n",
      "(13, '0.018*\"data\" + 0.016*\"time\" + 0.012*\"model\" + 0.011*\"pattern\" + 0.008*\"amazon\" + 0.007*\"many\" + 0.007*\"use\" + 0.007*\"forecasting\" + 0.007*\"one\" + 0.006*\"sale\"')\n",
      "\n",
      "Topic 15:\n",
      "(14, '0.015*\"machine\" + 0.014*\"amazon\" + 0.013*\"data\" + 0.013*\"learning\" + 0.009*\"use\" + 0.008*\"time\" + 0.007*\"section\" + 0.007*\"image\" + 0.006*\"model\" + 0.006*\"set\"')\n",
      "\n",
      "Topic 16:\n",
      "(15, '0.034*\"model\" + 0.024*\"feature\" + 0.022*\"data\" + 0.012*\"value\" + 0.009*\"need\" + 0.007*\"training\" + 0.007*\"outlier\" + 0.007*\"use\" + 0.006*\"example\" + 0.006*\"make\"')\n",
      "\n",
      "Topic 17:\n",
      "(16, '0.057*\"data\" + 0.019*\"model\" + 0.017*\"set\" + 0.012*\"amazon\" + 0.011*\"label\" + 0.011*\"also\" + 0.010*\"value\" + 0.010*\"learning\" + 0.010*\"use\" + 0.010*\"image\"')\n",
      "\n",
      "Topic 18:\n",
      "(17, '0.014*\"data\" + 0.013*\"amazon\" + 0.010*\"recognition\" + 0.010*\"face\" + 0.009*\"video\" + 0.008*\"image\" + 0.007*\"time\" + 0.007*\"might\" + 0.006*\"also\" + 0.005*\"stream\"')\n",
      "\n",
      "Topic 19:\n",
      "(18, '0.035*\"learning\" + 0.031*\"machine\" + 0.015*\"model\" + 0.015*\"module\" + 0.015*\"data\" + 0.015*\"problem\" + 0.012*\"section\" + 0.010*\"business\" + 0.010*\"use\" + 0.006*\"also\"')\n",
      "\n",
      "Topic 20:\n",
      "(19, '0.039*\"model\" + 0.029*\"learning\" + 0.020*\"machine\" + 0.019*\"data\" + 0.017*\"use\" + 0.009*\"section\" + 0.009*\"need\" + 0.008*\"problem\" + 0.007*\"prediction\" + 0.007*\"sagemaker\"')\n",
      "\n",
      "Topic 21:\n",
      "(20, '0.038*\"learning\" + 0.032*\"machine\" + 0.027*\"data\" + 0.012*\"section\" + 0.010*\"model\" + 0.010*\"use\" + 0.009*\"example\" + 0.008*\"problem\" + 0.008*\"module\" + 0.008*\"also\"')\n",
      "\n",
      "Topic 22:\n",
      "(21, '0.015*\"data\" + 0.010*\"time\" + 0.010*\"label\" + 0.009*\"model\" + 0.008*\"set\" + 0.008*\"image\" + 0.008*\"amazon\" + 0.008*\"algorithm\" + 0.008*\"use\" + 0.007*\"series\"')\n",
      "\n",
      "Topic 23:\n",
      "(22, '0.046*\"data\" + 0.020*\"use\" + 0.018*\"amazon\" + 0.016*\"model\" + 0.014*\"machine\" + 0.013*\"learning\" + 0.012*\"also\" + 0.010*\"aws\" + 0.008*\"set\" + 0.008*\"problem\"')\n",
      "\n",
      "Topic 24:\n",
      "(23, '0.041*\"data\" + 0.028*\"learning\" + 0.022*\"machine\" + 0.019*\"model\" + 0.015*\"use\" + 0.015*\"amazon\" + 0.009*\"problem\" + 0.009*\"aws\" + 0.008*\"image\" + 0.007*\"also\"')\n",
      "\n",
      "Topic 25:\n",
      "(24, '0.037*\"data\" + 0.033*\"model\" + 0.015*\"value\" + 0.012*\"problem\" + 0.011*\"example\" + 0.009*\"positive\" + 0.009*\"use\" + 0.009*\"cat\" + 0.008*\"metric\" + 0.008*\"missing\"')\n",
      "\n",
      "Topic 26:\n",
      "(25, '0.042*\"data\" + 0.009*\"learning\" + 0.009*\"model\" + 0.009*\"column\" + 0.008*\"set\" + 0.008*\"machine\" + 0.007*\"feature\" + 0.007*\"use\" + 0.007*\"training\" + 0.007*\"example\"')\n",
      "\n",
      "Topic 27:\n",
      "(26, '0.028*\"learning\" + 0.017*\"machine\" + 0.017*\"use\" + 0.015*\"data\" + 0.014*\"amazon\" + 0.011*\"model\" + 0.011*\"also\" + 0.009*\"image\" + 0.007*\"video\" + 0.007*\"section\"')\n",
      "\n",
      "Topic 28:\n",
      "(27, '0.029*\"amazon\" + 0.027*\"model\" + 0.025*\"data\" + 0.017*\"use\" + 0.013*\"image\" + 0.012*\"set\" + 0.010*\"learning\" + 0.009*\"also\" + 0.009*\"recognition\" + 0.008*\"section\"')\n",
      "\n",
      "Topic 29:\n",
      "(28, '0.024*\"learning\" + 0.022*\"data\" + 0.017*\"machine\" + 0.011*\"problem\" + 0.008*\"set\" + 0.008*\"model\" + 0.008*\"use\" + 0.007*\"training\" + 0.007*\"section\" + 0.007*\"amazon\"')\n",
      "\n",
      "Topic 30:\n",
      "(29, '0.061*\"data\" + 0.016*\"use\" + 0.016*\"model\" + 0.014*\"amazon\" + 0.014*\"set\" + 0.012*\"machine\" + 0.012*\"learning\" + 0.012*\"aws\" + 0.012*\"image\" + 0.010*\"also\"')\n",
      "\n",
      "Topic 31:\n",
      "(30, '0.017*\"model\" + 0.013*\"cat\" + 0.010*\"use\" + 0.010*\"mean\" + 0.010*\"number\" + 0.009*\"data\" + 0.009*\"positive\" + 0.008*\"metric\" + 0.007*\"correlation\" + 0.007*\"identified\"')\n",
      "\n",
      "Topic 32:\n",
      "(31, '0.025*\"model\" + 0.020*\"data\" + 0.018*\"use\" + 0.015*\"image\" + 0.014*\"word\" + 0.014*\"amazon\" + 0.011*\"machine\" + 0.010*\"example\" + 0.010*\"label\" + 0.009*\"learning\"')\n",
      "\n",
      "Topic 33:\n",
      "(32, '0.041*\"data\" + 0.027*\"model\" + 0.015*\"machine\" + 0.015*\"learning\" + 0.013*\"use\" + 0.012*\"need\" + 0.011*\"example\" + 0.010*\"image\" + 0.010*\"training\" + 0.009*\"amazon\"')\n",
      "\n",
      "Topic 34:\n",
      "(33, '0.041*\"data\" + 0.017*\"model\" + 0.017*\"amazon\" + 0.011*\"use\" + 0.009*\"aws\" + 0.009*\"also\" + 0.008*\"glue\" + 0.008*\"need\" + 0.007*\"face\" + 0.007*\"might\"')\n",
      "\n",
      "Topic 35:\n",
      "(34, '0.019*\"data\" + 0.016*\"learning\" + 0.016*\"model\" + 0.014*\"use\" + 0.013*\"amazon\" + 0.011*\"machine\" + 0.009*\"nlp\" + 0.008*\"training\" + 0.007*\"text\" + 0.007*\"algorithm\"')\n",
      "\n",
      "Topic 36:\n",
      "(35, '0.025*\"data\" + 0.025*\"value\" + 0.021*\"missing\" + 0.014*\"feature\" + 0.013*\"variable\" + 0.012*\"set\" + 0.010*\"outlier\" + 0.010*\"mean\" + 0.007*\"use\" + 0.007*\"also\"')\n",
      "\n",
      "Topic 37:\n",
      "(36, '0.038*\"amazon\" + 0.031*\"data\" + 0.028*\"forecast\" + 0.019*\"time\" + 0.014*\"use\" + 0.013*\"module\" + 0.011*\"learning\" + 0.010*\"series\" + 0.010*\"machine\" + 0.008*\"look\"')\n",
      "\n",
      "Topic 38:\n",
      "(37, '0.048*\"amazon\" + 0.025*\"use\" + 0.016*\"data\" + 0.011*\"application\" + 0.011*\"machine\" + 0.011*\"language\" + 0.010*\"also\" + 0.009*\"learning\" + 0.009*\"example\" + 0.009*\"model\"')\n",
      "\n",
      "Topic 39:\n",
      "(38, '0.020*\"nlp\" + 0.019*\"learning\" + 0.019*\"machine\" + 0.017*\"word\" + 0.013*\"data\" + 0.011*\"model\" + 0.010*\"text\" + 0.010*\"amazon\" + 0.009*\"example\" + 0.008*\"also\"')\n",
      "\n",
      "Topic 40:\n",
      "(39, '0.035*\"data\" + 0.021*\"learning\" + 0.019*\"machine\" + 0.015*\"model\" + 0.013*\"feature\" + 0.011*\"example\" + 0.009*\"use\" + 0.009*\"amazon\" + 0.007*\"also\" + 0.007*\"value\"')\n",
      "\n",
      "Topic 41:\n",
      "(40, '0.017*\"model\" + 0.015*\"use\" + 0.014*\"amazon\" + 0.013*\"data\" + 0.008*\"training\" + 0.007*\"number\" + 0.007*\"cat\" + 0.005*\"example\" + 0.005*\"used\" + 0.005*\"learning\"')\n",
      "\n",
      "Topic 42:\n",
      "(41, '0.014*\"model\" + 0.007*\"use\" + 0.006*\"metric\" + 0.005*\"positive\" + 0.004*\"mean\" + 0.004*\"outlier\" + 0.003*\"data\" + 0.003*\"feature\" + 0.003*\"false\" + 0.003*\"also\"')\n",
      "\n",
      "Topic 43:\n",
      "(42, '0.021*\"model\" + 0.015*\"use\" + 0.013*\"data\" + 0.012*\"training\" + 0.011*\"learning\" + 0.011*\"amazon\" + 0.010*\"image\" + 0.010*\"machine\" + 0.008*\"object\" + 0.007*\"label\"')\n",
      "\n",
      "Topic 44:\n",
      "(43, '0.037*\"cat\" + 0.029*\"model\" + 0.017*\"identified\" + 0.016*\"number\" + 0.013*\"correctly\" + 0.011*\"positive\" + 0.011*\"would\" + 0.010*\"image\" + 0.010*\"better\" + 0.010*\"negative\"')\n",
      "\n",
      "Topic 45:\n",
      "(44, '0.019*\"data\" + 0.016*\"machine\" + 0.015*\"learning\" + 0.013*\"time\" + 0.012*\"use\" + 0.011*\"forecast\" + 0.009*\"model\" + 0.009*\"value\" + 0.008*\"need\" + 0.006*\"amazon\"')\n",
      "\n",
      "Topic 46:\n",
      "(45, '0.031*\"model\" + 0.019*\"learning\" + 0.017*\"image\" + 0.016*\"use\" + 0.014*\"amazon\" + 0.014*\"machine\" + 0.014*\"training\" + 0.013*\"data\" + 0.013*\"label\" + 0.013*\"object\"')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "import os\n",
    "\n",
    "def extract_topics_from_folder(folder_path, num_topics=5, num_words=10):\n",
    "    preprocessed_texts = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.isfile(file_path):\n",
    "            with open(file_path, \"r\") as file:\n",
    "                preprocessed_text = file.read().split() \n",
    "                preprocessed_texts.append(preprocessed_text)\n",
    "\n",
    "    dictionary = corpora.Dictionary(preprocessed_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in preprocessed_texts]\n",
    "    \n",
    "    # Training the LDA model\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "    topics = lda_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "    return topics\n",
    "\n",
    "# Directory where preprocessed texts are saved\n",
    "preprocessed_texts_dir = \"preprocessed_texts\"\n",
    "\n",
    "num_topics = 46\n",
    "num_words = 10\n",
    "topics = extract_topics_from_folder(preprocessed_texts_dir, num_topics=num_topics, num_words=num_words)\n",
    "\n",
    "# Printing the extracted topics\n",
    "for i, topic in enumerate(topics):\n",
    "    print(f\"Topic {i+1}:\")\n",
    "    print(topic)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 Key Phrases: ['time series data', 'working time series', 'series data list', 'challenge working time', 'aws academy machine', 'academy machine learning', 'business problem solved', 'list step required', 'step required create', 'problem solved amazon']\n",
      "Text 1 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.025*\"forecast\" + 0.025*\"amazon\" + 0.025*\"module\" + 0.025*\"data\" + 0.025*\"look\"\n",
      "\n",
      "Text 2 Key Phrases: ['feature data set', 'data set information', 'data set made', 'scatter plot matrix', 'data set imbalance', 'imbalance data set', 'set imbalance data', 'relationship scatter plot', 'plot box plot', 'set information give']\n",
      "Text 2 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.033*\"data\" + 0.019*\"value\" + 0.014*\"feature\" + 0.011*\"variable\" + 0.011*\"might\"\n",
      "\n",
      "Text 3 Key Phrases: ['distributed training job', 'sagemaker hyperparameter tuning', 'metric training job', 'training job performs', 'result training job', 'training tuning machine', 'training job data', 'training job time', 'tuning job improves', 'process training tuning']\n",
      "Text 3 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.029*\"hyperparameters\" + 0.022*\"hyperparameter\" + 0.020*\"model\" + 0.019*\"training\" + 0.017*\"job\"\n",
      "\n",
      "Text 4 Key Phrases: ['amazon recognition custom', 'recognition custom label', 'train amazon recognition', 'machine learning process', 'learning amazon recognition', 'training data set', 'amazon recognition', 'training computer vision', 'amazon recognition detect', 'amazon recognition trained']\n",
      "Text 4 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.060*\"image\" + 0.037*\"model\" + 0.033*\"amazon\" + 0.028*\"recognition\" + 0.028*\"use\"\n",
      "\n",
      "Text 5 Key Phrases: ['business problem solved', 'series data list', 'data list step', 'list step required', 'step required create', 'problem solved amazon', 'back time review', 'review module wrap', 'wrap module learned', 'learned describe business']\n",
      "Text 5 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.055*\"forecast\" + 0.048*\"amazon\" + 0.048*\"module\" + 0.047*\"describe\" + 0.046*\"time\"\n",
      "\n",
      "Text 6 Key Phrases: ['case amazon comprehend', 'amazon translate create', 'amazon comprehend amazon', 'amazon polly convert', 'case amazon polly', 'case amazon translate', 'amazon transcribe capture', 'case amazon transcribe', 'application amazon translate', 'language amazon translate']\n",
      "Text 6 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.037*\"amazon\" + 0.020*\"use\" + 0.012*\"application\" + 0.011*\"translate\" + 0.010*\"comprehend\"\n",
      "\n",
      "Text 7 Key Phrases: ['wrap knowledge check', 'learned formulate problem', 'formulate problem business', 'problem business request', 'business request obtain', 'request obtain secure', 'build jupyter notebook', 'open source tool', 'source tool examine', 'cross validation test']\n",
      "Text 7 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.045*\"use\" + 0.043*\"data\" + 0.040*\"model\" + 0.036*\"module\" + 0.035*\"amazon\"\n",
      "\n",
      "Text 8 Key Phrases: ['time series data', 'finally grain time', 'time time series', 'missing sale data', 'series data data', 'situation demand forecasting', 'retail missing sale', 'time series specific', 'calculate missing data', 'missing data case']\n",
      "Text 8 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.051*\"data\" + 0.019*\"time\" + 0.015*\"missing\" + 0.014*\"might\" + 0.014*\"sale\"\n",
      "\n",
      "Text 9 Key Phrases: ['part artificial intelligence', 'solve business problem', 'business problem solved', 'artificial intelligence machine', 'challenge face completing', 'traditional software development', 'software development method', 'development method ready', 'problem solved machine', 'learning part artificial']\n",
      "Text 9 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.063*\"machine\" + 0.042*\"learning\" + 0.026*\"module\" + 0.025*\"tool\" + 0.024*\"describe\"\n",
      "\n",
      "Text 10 Key Phrases: ['time series data', 'opportunity predicting future', 'component add additional', 'year month day', 'series data falling', 'area machine learning', 'predicting future outcome', 'future outcome based', 'outcome based historical', 'add additional information']\n",
      "Text 10 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.041*\"time\" + 0.035*\"pattern\" + 0.032*\"forecasting\" + 0.024*\"data\" + 0.020*\"one\"\n",
      "\n",
      "Text 11 Key Phrases: ['obtain data multiple', 'access resource make', 'make easy obtain', 'history play account', 'retain account activity', 'account activity related', 'play account activity', 'account activity including', 'secure transport layer', 'store finally make']\n",
      "Text 11 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.054*\"data\" + 0.030*\"aws\" + 0.016*\"secure\" + 0.015*\"access\" + 0.014*\"service\"\n",
      "\n",
      "Text 12 Key Phrases: ['amazon recognition video', 'recognition video stream', 'application amazon recognition', 'amazon recognition', 'streaming amazon recognition', 'stream amazon recognition', 'recognition video amazon', 'video amazon recognition', 'collection amazon recognition', 'recognition video streaming']\n",
      "Text 12 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.048*\"video\" + 0.035*\"amazon\" + 0.033*\"face\" + 0.032*\"recognition\" + 0.029*\"image\"\n",
      "\n",
      "Text 13 Key Phrases: ['machine learning problem', 'challenge machine learning', 'machine learning', 'machine learning lot', 'formulating machine learning', 'operating machine learning', 'substantial machine learning', 'machine learning knowledge', 'machine learning add', 'sophisticated machine learning']\n",
      "Text 13 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.030*\"machine\" + 0.025*\"learning\" + 0.022*\"data\" + 0.018*\"model\" + 0.015*\"problem\"\n",
      "\n",
      "Text 14 Key Phrases: ['amazon recognition custom', 'recognition custom label', 'detect custom label', 'custom label operation', 'returned detect custom', 'custom label returned', 'custom label includes', 'model calculated threshold', 'object custom label', 'training data set']\n",
      "Text 14 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.045*\"label\" + 0.041*\"model\" + 0.037*\"image\" + 0.023*\"object\" + 0.023*\"custom\"\n",
      "\n",
      "Text 15 Key Phrases: ['amazon sagemaker algorithm', 'amazon sagemaker provides', 'amazon sagemaker includes', 'problem amazon sagemaker', 'model amazon sagemaker', 'sagemaker amazon sagemaker', 'amazon sagemaker amazon', 'amazon sagemaker', 'learning amazon sagemaker', 'format amazon sagemaker']\n",
      "Text 15 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.027*\"data\" + 0.022*\"training\" + 0.018*\"model\" + 0.018*\"algorithm\" + 0.015*\"amazon\"\n",
      "\n",
      "Text 16 Key Phrases: ['natural language processing', 'managed amazon service', 'introduction natural language', 'introduce natural language', 'amazon service describe', 'describe managed amazon', 'learning introduction natural', 'aws academy machine', 'academy machine learning', 'machine learning introduction']\n",
      "Text 16 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.045*\"nlp\" + 0.029*\"language\" + 0.029*\"describe\" + 0.028*\"module\" + 0.026*\"development\"\n",
      "\n",
      "Text 17 Key Phrases: ['prepare custom data', 'custom data set', 'time summarize main', 'required prepare custom', 'data set object', 'summarize main point', 'management learning service', 'analysis list step', 'list step required', 'sagemaker ground truth']\n",
      "Text 17 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.052*\"describe\" + 0.042*\"amazon\" + 0.036*\"set\" + 0.035*\"prepare\" + 0.034*\"vision\"\n",
      "\n",
      "Text 18 Key Phrases: ['total number actual', 'cat correctly identified', 'correctly identified cat', 'divide total number', 'choose wanted make', 'number actual cat', 'positive identification cat', 'correctly identified divided', 'work correctly identified', 'correctly identified calculate']\n",
      "Text 18 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.068*\"cat\" + 0.050*\"model\" + 0.029*\"number\" + 0.026*\"positive\" + 0.025*\"identified\"\n",
      "\n",
      "Text 19 Key Phrases: ['data multiple column', 'ordinary multiple column', 'machine learning model', 'section machine learning', 'improve machine learning', 'specific machine learning', 'machine learning algorithm', 'make model successful', 'text column numerical', 'multiple column feature']\n",
      "Text 19 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.028*\"feature\" + 0.025*\"data\" + 0.015*\"value\" + 0.012*\"column\" + 0.011*\"numerical\"\n",
      "\n",
      "Text 20 Key Phrases: ['multi model endpoint', 'deploy model amazon', 'prediction entire data', 'deploy train model', 'host multiple model', 'model create endpoint', 'entire data set', 'data processing step', 'prediction deploy model', 'model amazon sagemaker']\n",
      "Text 20 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.032*\"model\" + 0.015*\"endpoint\" + 0.013*\"sagemaker\" + 0.012*\"data\" + 0.012*\"prediction\"\n",
      "\n",
      "Text 21 Key Phrases: ['model training data', 'training data model', 'overfitting training data', 'time train model', 'model training model', 'train model training', 'age birth month', 'training data perform', 'model overfitting training', 'training model evaluation']\n",
      "Text 21 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.041*\"data\" + 0.037*\"model\" + 0.014*\"feature\" + 0.011*\"later\" + 0.010*\"training\"\n",
      "\n",
      "Text 22 Key Phrases: ['system convert text', 'convert text data', 'human machine interaction', 'task nlp application', 'form word run', 'natural language processing', 'system machine learning', 'inverse document frequency', 'number time word', 'form machine learning']\n",
      "Text 22 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.045*\"word\" + 0.026*\"nlp\" + 0.020*\"text\" + 0.015*\"example\" + 0.012*\"application\"\n",
      "\n",
      "Text 23 Key Phrases: ['great topic today', 'explore detail analyzing', 'analysis list step', 'list step required', 'sagemaker ground truth', 'recognition perform facial', 'detail analyzing image', 'academy machine learning', 'customized data set', 'data set performing']\n",
      "Text 23 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.036*\"use\" + 0.028*\"service\" + 0.028*\"detection\" + 0.026*\"computer\" + 0.026*\"amazon\"\n",
      "\n",
      "Text 24 Key Phrases: ['machine learning model', 'machine learning pipeline', 'data machine learning', 'machine learning problem', 'credit card transaction', 'reduction number customer', 'machine learning', 'make prediction section', 'machine learning make', 'reminder machine learning']\n",
      "Text 24 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.035*\"data\" + 0.027*\"problem\" + 0.024*\"machine\" + 0.021*\"section\" + 0.018*\"learning\"\n",
      "\n",
      "Text 25 Key Phrases: ['time series data', 'series data set', 'include time series', 'wrangling time series', 'random time series', 'face time series', 'independent time series', 'time series refer', 'excellent time series', 'handling time series']\n",
      "Text 25 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.014*\"data\" + 0.014*\"time\" + 0.012*\"series\" + 0.011*\"correlation\" + 0.010*\"algorithm\"\n",
      "\n",
      "Text 26 Key Phrases: ['source data set', 'run training job', 'target answer prediction', 'data machine learning', 'credit card fraud', 'open source data', 'predict credit card', 'training job amazon', 'relational database service', 'training data amazon']\n",
      "Text 26 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.040*\"data\" + 0.014*\"training\" + 0.013*\"amazon\" + 0.010*\"use\" + 0.010*\"target\"\n",
      "\n",
      "Text 27 Key Phrases: ['artificial intelligence machine', 'part artificial intelligence', 'stage developing machine', 'discussing challenge machine', 'learned recognize machine', 'intelligence machine learning', 'intelligence describe artificial', 'describe artificial intelligence', 'artificial intelligence describe', 'machine learning']\n",
      "Text 27 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.022*\"machine\" + 0.022*\"learning\" + 0.017*\"looked\" + 0.017*\"module\" + 0.017*\"solve\"\n",
      "\n",
      "Text 28 Key Phrases: ['machine learning program', 'reinforcement learning model', 'learning supervised learning', 'learning reinforcement learning', 'learning program trained', 'machine learning supervised', 'machine learning reinforcement', 'problem machine learning', 'machine learning problem', 'unsupervised machine learning']\n",
      "Text 28 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.030*\"learning\" + 0.014*\"problem\" + 0.013*\"machine\" + 0.011*\"example\" + 0.009*\"data\"\n",
      "\n",
      "Text 29 Key Phrases: ['clean data set', 'data set missing', 'set missing data', 'variable describes number', 'missing data make', 'drop impute missing', 'missing data data', 'row missing data', 'missing data drop', 'missing data decide']\n",
      "Text 29 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.032*\"value\" + 0.032*\"data\" + 0.022*\"variable\" + 0.022*\"missing\" + 0.015*\"set\"\n",
      "\n",
      "Text 30 Key Phrases: ['machine learning framework', 'open source machine', 'lab open source', 'machine learning', 'source machine learning', 'notebook open source', 'open source web', 'open source python', 'computing machine learning', 'jupiter lab open']\n",
      "Text 30 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.024*\"amazon\" + 0.021*\"machine\" + 0.016*\"learning\" + 0.016*\"also\" + 0.014*\"data\"\n",
      "\n",
      "Text 31 Key Phrases: ['box plot show', 'feature selection method', 'selection start feature', 'feature training model', 'plot box plot', 'method embedded method', 'method filter method', 'selection method filter', 'box plot box', 'method involve training']\n",
      "Text 31 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.030*\"feature\" + 0.024*\"model\" + 0.021*\"outlier\" + 0.020*\"data\" + 0.019*\"method\"\n",
      "\n",
      "Text 32 Key Phrases: ['amazon recognition custom', 'recognition custom label', 'test data set', 'entire test data', 'custom label return', 'custom label test', 'image test data', 'metric entire test', 'presence custom label', 'custom label present']\n",
      "Text 32 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.068*\"label\" + 0.042*\"model\" + 0.040*\"set\" + 0.036*\"data\" + 0.034*\"test\"\n",
      "\n",
      "Text 33 Key Phrases: ['time series data', 'quantile predicts time', 'predicts time true', 'time fewer pair', 'fewer pair sold', 'amazon forecast create', 'amazon forecast train', 'sold time fewer', 'pair sold time', 'weighted quantile loss']\n",
      "Text 33 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.029*\"forecast\" + 0.024*\"data\" + 0.018*\"quantile\" + 0.016*\"time\" + 0.015*\"amazon\"\n",
      "\n",
      "Text 34 Key Phrases: ['machine learning pipeline', 'machine learning section', 'machine learning', 'machine learning problem', 'certified machine learning', 'statistic machine learning', 'implement machine learning', 'machine learning specialty', 'machine learning engineer', 'amazon machine learning']\n",
      "Text 34 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.048*\"machine\" + 0.042*\"learning\" + 0.023*\"data\" + 0.022*\"section\" + 0.016*\"module\"\n",
      "\n",
      "Text 35 Key Phrases: ['machine learning model', 'machine learning pipeline', 'machine learning problem', 'amazon sagemaker outline', 'amazon sagemaker train', 'learning pipeline applied', 'academy machine learning', 'entire machine learning', 'handling machine learning', 'type machine learning']\n",
      "Text 35 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.021*\"learning\" + 0.021*\"machine\" + 0.018*\"data\" + 0.018*\"module\" + 0.017*\"process\"\n",
      "\n",
      "Text 36 Key Phrases: ['amazon recognition analyzes', 'result amazon recognition', 'recognition analyzes image', 'amazon recognition', 'recognition amazon recognition', 'image inappropriate content', 'amazon recognition amazon', 'image stored video', 'amazon recognition performs', 'video amazon recognition']\n",
      "Text 36 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.022*\"amazon\" + 0.018*\"image\" + 0.014*\"recognition\" + 0.010*\"object\" + 0.010*\"content\"\n",
      "\n",
      "Text 37 Key Phrases: ['case computer vision', 'computer vision automated', 'computer vision technology', 'vision automated extraction', 'vision computer vision', 'computer vision computer', 'computer vision', 'automated extraction information', 'technology computer vision', 'vision technology computer']\n",
      "Text 37 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.022*\"computer\" + 0.019*\"vision\" + 0.017*\"image\" + 0.014*\"object\" + 0.009*\"use\"\n",
      "\n",
      "Text 38 Key Phrases: ['aws glue data', 'glue data catalog', 'catalog aws glue', 'aws glue', 'extract transform load', 'set aws glue', 'store aws glue', 'aws glue service', 'aws glue run', 'aws glue console']\n",
      "Text 38 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.068*\"data\" + 0.028*\"glue\" + 0.025*\"aws\" + 0.022*\"etl\" + 0.017*\"job\"\n",
      "\n",
      "Text 39 Key Phrases: ['quantify linear relationship', 'weak linear relationship', 'linear relationship quantified', 'relationship indication linear', 'indication linear relationship', 'minus linear relationship', 'set quantify linear', 'proportional minus linear', 'strong weak linear', 'seaborne heat map']\n",
      "Text 39 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.042*\"correlation\" + 0.028*\"relationship\" + 0.023*\"data\" + 0.023*\"linear\" + 0.021*\"variable\"\n",
      "\n",
      "Text 40 Key Phrases: ['sagemaker ground truth', 'automated data labeling', 'amazon recognition custom', 'recognition custom label', 'label data set', 'data set data', 'labeling sagemaker ground', 'training data set', 'human label data', 'set data set']\n",
      "Text 40 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.045*\"image\" + 0.044*\"data\" + 0.038*\"label\" + 0.027*\"sagemaker\" + 0.024*\"set\"\n",
      "\n",
      "Text 41 Key Phrases: ['false positive rate', 'positive false positive', 'difference prediction actual', 'positive rate false', 'rate false positive', 'true positive rate', 'email message spam', 'sensitivity true positive', 'calculate false positive', 'false positive high']\n",
      "Text 41 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.016*\"model\" + 0.012*\"metric\" + 0.009*\"positive\" + 0.009*\"use\" + 0.007*\"prediction\"\n",
      "\n",
      "Text 42 Key Phrases: ['back time review', 'nlp good job', 'time review module', 'wrap summary module', 'review module wrap', 'module wrap summary', 'summary module learn', 'learn describe nlp', 'managed amazon service', 'amazon service describe']\n",
      "Text 42 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.042*\"module\" + 0.042*\"back\" + 0.042*\"service\" + 0.042*\"nlp\" + 0.042*\"amazon\"\n",
      "\n",
      "Text 43 Key Phrases: ['predicted label class', 'cat predicted class', 'class actual label', 'actual label class', 'label class cat', 'good outcome model', 'similarly actual label', 'label cat identified', 'comparison predicted class', 'predicted class matched']\n",
      "Text 43 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.031*\"model\" + 0.030*\"cat\" + 0.028*\"metric\" + 0.023*\"class\" + 0.022*\"predicted\"\n",
      "\n",
      "Text 44 Key Phrases: ['certified machine learning', 'machine learning specialty', 'aws certified machine', 'academy machine learning', 'machine learning solution', 'implement machine learning', 'aws academy machine', 'completing aws academy', 'congratulation completing aws', 'machine learning']\n",
      "Text 44 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.023*\"learning\" + 0.023*\"aws\" + 0.023*\"machine\" + 0.021*\"certification\" + 0.019*\"exam\"\n",
      "\n",
      "Text 45 Key Phrases: ['machine learning subset', 'learning practitioner spend', 'building machine perform', 'artificial intelligence broad', 'machine deep learning', 'layer artificial neuron', 'intelligence machine learning', 'machine learning', 'algorithm statistical model', 'deep learning practitioner']\n",
      "Text 45 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.016*\"learning\" + 0.016*\"machine\" + 0.012*\"deep\" + 0.009*\"artificial\" + 0.009*\"output\"\n",
      "\n",
      "Text 46 Key Phrases: ['correct data type', 'data frame row', 'visualize analyze data', 'frame row label', 'column data frame', 'load data frame', 'row column column', 'row label column', 'row column format', 'type load data']\n",
      "Text 46 Topics:\n",
      "Topic 1: 0\n",
      "Topic 2: 0.024*\"data\" + 0.016*\"column\" + 0.011*\"type\" + 0.010*\"frame\" + 0.009*\"format\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake\n",
    "from gensim import corpora, models\n",
    "\n",
    "# Define function to extract key phrases using YAKE\n",
    "def extract_key_phrases(text):\n",
    "    \n",
    "    language = \"en\"\n",
    "    max_ngram_size = 3\n",
    "    deduplication_threshold = 0.9\n",
    "    deduplication_algo = 'seqm'\n",
    "    window_size = 1\n",
    "    num_keywords = 10 \n",
    "    custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold,\n",
    "                                                dedupFunc=deduplication_algo, windowsSize=window_size, top=num_keywords, features=None)\n",
    "\n",
    "\n",
    "    keywords = custom_kw_extractor.extract_keywords(text)\n",
    "    key_phrases = [keyphrase for keyphrase, _ in keywords]\n",
    "    return key_phrases\n",
    "\n",
    "# Defining function to extract topics using Gensim LDA\n",
    "def extract_topics(texts, num_topics=5, num_words=5):\n",
    "    tokenized_texts = [text.split() for text in texts]\n",
    "    dictionary = corpora.Dictionary(tokenized_texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "    lda_model = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "    topics = lda_model.print_topics(num_topics=num_topics, num_words=num_words)\n",
    "    return topics\n",
    "\n",
    "directory_path = \"preprocessed_texts\"\n",
    "\n",
    "def read_text_files(directory_path):\n",
    "    text_data = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        filepath = os.path.join(directory_path, filename)\n",
    "        if os.path.isfile(filepath):  # Check if the path is a file\n",
    "            with open(filepath, 'r') as file:\n",
    "                text = file.read()\n",
    "                text_data.append(text)\n",
    "    return text_data\n",
    "\n",
    "text_data = read_text_files(directory_path)\n",
    "\n",
    "key_phrases_list = []\n",
    "topics_list = []\n",
    "\n",
    "for text in text_data:\n",
    "    \n",
    "    key_phrases = extract_key_phrases(text)\n",
    "    key_phrases_list.append(key_phrases)\n",
    "   \n",
    "    topics = extract_topics([text])[0]  # Assuming only one text per iteration\n",
    "    topics_list.append(topics)\n",
    "\n",
    "for i, (key_phrases, topics) in enumerate(zip(key_phrases_list, topics_list), start=1):\n",
    "    print(f\"Text {i} Key Phrases:\", key_phrases)\n",
    "    print(f\"Text {i} Topics:\")\n",
    "    for j, topic in enumerate(topics, start=1):\n",
    "        print(f\"Topic {j}: {topic}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Topic 1': ['time series data', 'working time series', 'series data list', 'challenge working time', 'aws academy machine', 'academy machine learning', 'business problem solved', 'list step required', 'step required create', 'problem solved amazon'], 'Topic 2': ['feature data set', 'data set information', 'data set made', 'scatter plot matrix', 'data set imbalance', 'imbalance data set', 'set imbalance data', 'relationship scatter plot', 'plot box plot', 'set information give'], 'Topic 3': ['distributed training job', 'sagemaker hyperparameter tuning', 'metric training job', 'training job performs', 'result training job', 'training tuning machine', 'training job data', 'training job time', 'tuning job improves', 'process training tuning'], 'Topic 4': ['amazon recognition custom', 'recognition custom label', 'train amazon recognition', 'machine learning process', 'learning amazon recognition', 'training data set', 'amazon recognition', 'training computer vision', 'amazon recognition detect', 'amazon recognition trained'], 'Topic 5': ['business problem solved', 'series data list', 'data list step', 'list step required', 'step required create', 'problem solved amazon', 'back time review', 'review module wrap', 'wrap module learned', 'learned describe business'], 'Topic 6': ['case amazon comprehend', 'amazon translate create', 'amazon comprehend amazon', 'amazon polly convert', 'case amazon polly', 'case amazon translate', 'amazon transcribe capture', 'case amazon transcribe', 'application amazon translate', 'language amazon translate'], 'Topic 7': ['wrap knowledge check', 'learned formulate problem', 'formulate problem business', 'problem business request', 'business request obtain', 'request obtain secure', 'build jupyter notebook', 'open source tool', 'source tool examine', 'cross validation test'], 'Topic 8': ['time series data', 'finally grain time', 'time time series', 'missing sale data', 'series data data', 'situation demand forecasting', 'retail missing sale', 'time series specific', 'calculate missing data', 'missing data case'], 'Topic 9': ['part artificial intelligence', 'solve business problem', 'business problem solved', 'artificial intelligence machine', 'challenge face completing', 'traditional software development', 'software development method', 'development method ready', 'problem solved machine', 'learning part artificial'], 'Topic 10': ['time series data', 'opportunity predicting future', 'component add additional', 'year month day', 'series data falling', 'area machine learning', 'predicting future outcome', 'future outcome based', 'outcome based historical', 'add additional information'], 'Topic 11': ['obtain data multiple', 'access resource make', 'make easy obtain', 'history play account', 'retain account activity', 'account activity related', 'play account activity', 'account activity including', 'secure transport layer', 'store finally make'], 'Topic 12': ['amazon recognition video', 'recognition video stream', 'application amazon recognition', 'amazon recognition', 'streaming amazon recognition', 'stream amazon recognition', 'recognition video amazon', 'video amazon recognition', 'collection amazon recognition', 'recognition video streaming'], 'Topic 13': ['machine learning problem', 'challenge machine learning', 'machine learning', 'machine learning lot', 'formulating machine learning', 'operating machine learning', 'substantial machine learning', 'machine learning knowledge', 'machine learning add', 'sophisticated machine learning'], 'Topic 14': ['amazon recognition custom', 'recognition custom label', 'detect custom label', 'custom label operation', 'returned detect custom', 'custom label returned', 'custom label includes', 'model calculated threshold', 'object custom label', 'training data set'], 'Topic 15': ['amazon sagemaker algorithm', 'amazon sagemaker provides', 'amazon sagemaker includes', 'problem amazon sagemaker', 'model amazon sagemaker', 'sagemaker amazon sagemaker', 'amazon sagemaker amazon', 'amazon sagemaker', 'learning amazon sagemaker', 'format amazon sagemaker'], 'Topic 16': ['natural language processing', 'managed amazon service', 'introduction natural language', 'introduce natural language', 'amazon service describe', 'describe managed amazon', 'learning introduction natural', 'aws academy machine', 'academy machine learning', 'machine learning introduction'], 'Topic 17': ['prepare custom data', 'custom data set', 'time summarize main', 'required prepare custom', 'data set object', 'summarize main point', 'management learning service', 'analysis list step', 'list step required', 'sagemaker ground truth'], 'Topic 18': ['total number actual', 'cat correctly identified', 'correctly identified cat', 'divide total number', 'choose wanted make', 'number actual cat', 'positive identification cat', 'correctly identified divided', 'work correctly identified', 'correctly identified calculate'], 'Topic 19': ['data multiple column', 'ordinary multiple column', 'machine learning model', 'section machine learning', 'improve machine learning', 'specific machine learning', 'machine learning algorithm', 'make model successful', 'text column numerical', 'multiple column feature'], 'Topic 20': ['multi model endpoint', 'deploy model amazon', 'prediction entire data', 'deploy train model', 'host multiple model', 'model create endpoint', 'entire data set', 'data processing step', 'prediction deploy model', 'model amazon sagemaker'], 'Topic 21': ['model training data', 'training data model', 'overfitting training data', 'time train model', 'model training model', 'train model training', 'age birth month', 'training data perform', 'model overfitting training', 'training model evaluation'], 'Topic 22': ['system convert text', 'convert text data', 'human machine interaction', 'task nlp application', 'form word run', 'natural language processing', 'system machine learning', 'inverse document frequency', 'number time word', 'form machine learning'], 'Topic 23': ['great topic today', 'explore detail analyzing', 'analysis list step', 'list step required', 'sagemaker ground truth', 'recognition perform facial', 'detail analyzing image', 'academy machine learning', 'customized data set', 'data set performing'], 'Topic 24': ['machine learning model', 'machine learning pipeline', 'data machine learning', 'machine learning problem', 'credit card transaction', 'reduction number customer', 'machine learning', 'make prediction section', 'machine learning make', 'reminder machine learning'], 'Topic 25': ['time series data', 'series data set', 'include time series', 'wrangling time series', 'random time series', 'face time series', 'independent time series', 'time series refer', 'excellent time series', 'handling time series'], 'Topic 26': ['source data set', 'run training job', 'target answer prediction', 'data machine learning', 'credit card fraud', 'open source data', 'predict credit card', 'training job amazon', 'relational database service', 'training data amazon'], 'Topic 27': ['artificial intelligence machine', 'part artificial intelligence', 'stage developing machine', 'discussing challenge machine', 'learned recognize machine', 'intelligence machine learning', 'intelligence describe artificial', 'describe artificial intelligence', 'artificial intelligence describe', 'machine learning'], 'Topic 28': ['machine learning program', 'reinforcement learning model', 'learning supervised learning', 'learning reinforcement learning', 'learning program trained', 'machine learning supervised', 'machine learning reinforcement', 'problem machine learning', 'machine learning problem', 'unsupervised machine learning'], 'Topic 29': ['clean data set', 'data set missing', 'set missing data', 'variable describes number', 'missing data make', 'drop impute missing', 'missing data data', 'row missing data', 'missing data drop', 'missing data decide'], 'Topic 30': ['machine learning framework', 'open source machine', 'lab open source', 'machine learning', 'source machine learning', 'notebook open source', 'open source web', 'open source python', 'computing machine learning', 'jupiter lab open'], 'Topic 31': ['box plot show', 'feature selection method', 'selection start feature', 'feature training model', 'plot box plot', 'method embedded method', 'method filter method', 'selection method filter', 'box plot box', 'method involve training'], 'Topic 32': ['amazon recognition custom', 'recognition custom label', 'test data set', 'entire test data', 'custom label return', 'custom label test', 'image test data', 'metric entire test', 'presence custom label', 'custom label present'], 'Topic 33': ['time series data', 'quantile predicts time', 'predicts time true', 'time fewer pair', 'fewer pair sold', 'amazon forecast create', 'amazon forecast train', 'sold time fewer', 'pair sold time', 'weighted quantile loss'], 'Topic 34': ['machine learning pipeline', 'machine learning section', 'machine learning', 'machine learning problem', 'certified machine learning', 'statistic machine learning', 'implement machine learning', 'machine learning specialty', 'machine learning engineer', 'amazon machine learning'], 'Topic 35': ['machine learning model', 'machine learning pipeline', 'machine learning problem', 'amazon sagemaker outline', 'amazon sagemaker train', 'learning pipeline applied', 'academy machine learning', 'entire machine learning', 'handling machine learning', 'type machine learning'], 'Topic 36': ['amazon recognition analyzes', 'result amazon recognition', 'recognition analyzes image', 'amazon recognition', 'recognition amazon recognition', 'image inappropriate content', 'amazon recognition amazon', 'image stored video', 'amazon recognition performs', 'video amazon recognition'], 'Topic 37': ['case computer vision', 'computer vision automated', 'computer vision technology', 'vision automated extraction', 'vision computer vision', 'computer vision computer', 'computer vision', 'automated extraction information', 'technology computer vision', 'vision technology computer'], 'Topic 38': ['aws glue data', 'glue data catalog', 'catalog aws glue', 'aws glue', 'extract transform load', 'set aws glue', 'store aws glue', 'aws glue service', 'aws glue run', 'aws glue console'], 'Topic 39': ['quantify linear relationship', 'weak linear relationship', 'linear relationship quantified', 'relationship indication linear', 'indication linear relationship', 'minus linear relationship', 'set quantify linear', 'proportional minus linear', 'strong weak linear', 'seaborne heat map'], 'Topic 40': ['sagemaker ground truth', 'automated data labeling', 'amazon recognition custom', 'recognition custom label', 'label data set', 'data set data', 'labeling sagemaker ground', 'training data set', 'human label data', 'set data set'], 'Topic 41': ['false positive rate', 'positive false positive', 'difference prediction actual', 'positive rate false', 'rate false positive', 'true positive rate', 'email message spam', 'sensitivity true positive', 'calculate false positive', 'false positive high'], 'Topic 42': ['back time review', 'nlp good job', 'time review module', 'wrap summary module', 'review module wrap', 'module wrap summary', 'summary module learn', 'learn describe nlp', 'managed amazon service', 'amazon service describe'], 'Topic 43': ['predicted label class', 'cat predicted class', 'class actual label', 'actual label class', 'label class cat', 'good outcome model', 'similarly actual label', 'label cat identified', 'comparison predicted class', 'predicted class matched'], 'Topic 44': ['certified machine learning', 'machine learning specialty', 'aws certified machine', 'academy machine learning', 'machine learning solution', 'implement machine learning', 'aws academy machine', 'completing aws academy', 'congratulation completing aws', 'machine learning'], 'Topic 45': ['machine learning subset', 'learning practitioner spend', 'building machine perform', 'artificial intelligence broad', 'machine deep learning', 'layer artificial neuron', 'intelligence machine learning', 'machine learning', 'algorithm statistical model', 'deep learning practitioner'], 'Topic 46': ['correct data type', 'data frame row', 'visualize analyze data', 'frame row label', 'column data frame', 'load data frame', 'row column column', 'row label column', 'row column format', 'type load data']}\n"
     ]
    }
   ],
   "source": [
    "topic_key_phrases = {}\n",
    "\n",
    "for i, key_phrases in enumerate(key_phrases_list, start=1):\n",
    "    topic_key_phrases[f\"Topic {i}\"] = key_phrases\n",
    "\n",
    "# Print the dictionary\n",
    "print(topic_key_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mod04_Intro': ['time series data', 'working time series', 'series data list', 'challenge working time', 'aws academy machine', 'academy machine learning', 'business problem solved', 'list step required', 'step required create', 'problem solved amazon'], 'Mod03_Sect03_part2': ['feature data set', 'data set information', 'data set made', 'scatter plot matrix', 'data set imbalance', 'imbalance data set', 'set imbalance data', 'relationship scatter plot', 'plot box plot', 'set information give'], 'Mod03_Sect08': ['distributed training job', 'sagemaker hyperparameter tuning', 'metric training job', 'training job performs', 'result training job', 'training tuning machine', 'training job data', 'training job time', 'tuning job improves', 'process training tuning'], 'Mod05_Sect03_part1': ['amazon recognition custom', 'recognition custom label', 'train amazon recognition', 'machine learning process', 'learning amazon recognition', 'training data set', 'amazon recognition', 'training computer vision', 'amazon recognition detect', 'amazon recognition trained'], 'Mod04_WrapUp': ['business problem solved', 'series data list', 'data list step', 'list step required', 'step required create', 'problem solved amazon', 'back time review', 'review module wrap', 'wrap module learned', 'learned describe business'], 'Mod06_Sect02': ['case amazon comprehend', 'amazon translate create', 'amazon comprehend amazon', 'amazon polly convert', 'case amazon polly', 'case amazon translate', 'amazon transcribe capture', 'case amazon transcribe', 'application amazon translate', 'language amazon translate'], 'Mod03_WrapUp': ['wrap knowledge check', 'learned formulate problem', 'formulate problem business', 'problem business request', 'business request obtain', 'request obtain secure', 'build jupyter notebook', 'open source tool', 'source tool examine', 'cross validation test'], 'Mod04_Sect02_part1': ['time series data', 'finally grain time', 'time time series', 'missing sale data', 'series data data', 'situation demand forecasting', 'retail missing sale', 'time series specific', 'calculate missing data', 'missing data case'], 'Mod02_Intro': ['part artificial intelligence', 'solve business problem', 'business problem solved', 'artificial intelligence machine', 'challenge face completing', 'traditional software development', 'software development method', 'development method ready', 'problem solved machine', 'learning part artificial'], 'Mod04_Sect01': ['time series data', 'opportunity predicting future', 'component add additional', 'year month day', 'series data falling', 'area machine learning', 'predicting future outcome', 'future outcome based', 'outcome based historical', 'add additional information'], 'Mod03_Sect02_part3': ['obtain data multiple', 'access resource make', 'make easy obtain', 'history play account', 'retain account activity', 'account activity related', 'play account activity', 'account activity including', 'secure transport layer', 'store finally make'], 'Mod05_Sect02_part2': ['amazon recognition video', 'recognition video stream', 'application amazon recognition', 'amazon recognition', 'streaming amazon recognition', 'stream amazon recognition', 'recognition video amazon', 'video amazon recognition', 'collection amazon recognition', 'recognition video streaming'], 'Mod02_Sect05': ['machine learning problem', 'challenge machine learning', 'machine learning', 'machine learning lot', 'formulating machine learning', 'operating machine learning', 'substantial machine learning', 'machine learning knowledge', 'machine learning add', 'sophisticated machine learning'], 'Mod05_Sect03_part4_ver2': ['amazon recognition custom', 'recognition custom label', 'detect custom label', 'custom label operation', 'returned detect custom', 'custom label returned', 'custom label includes', 'model calculated threshold', 'object custom label', 'training data set'], 'Mod03_Sect05': ['amazon sagemaker algorithm', 'amazon sagemaker provides', 'amazon sagemaker includes', 'problem amazon sagemaker', 'model amazon sagemaker', 'sagemaker amazon sagemaker', 'amazon sagemaker amazon', 'amazon sagemaker', 'learning amazon sagemaker', 'format amazon sagemaker'], 'Mod06_Intro': ['natural language processing', 'managed amazon service', 'introduction natural language', 'introduce natural language', 'amazon service describe', 'describe managed amazon', 'learning introduction natural', 'aws academy machine', 'academy machine learning', 'machine learning introduction'], 'Mod05_WrapUp_ver2': ['prepare custom data', 'custom data set', 'time summarize main', 'required prepare custom', 'data set object', 'summarize main point', 'management learning service', 'analysis list step', 'list step required', 'sagemaker ground truth'], 'Mod03_Sect07_part2': ['total number actual', 'cat correctly identified', 'correctly identified cat', 'divide total number', 'choose wanted make', 'number actual cat', 'positive identification cat', 'correctly identified divided', 'work correctly identified', 'correctly identified calculate'], 'Mod03_Sect04_part1': ['data multiple column', 'ordinary multiple column', 'machine learning model', 'section machine learning', 'improve machine learning', 'specific machine learning', 'machine learning algorithm', 'make model successful', 'text column numerical', 'multiple column feature'], 'Mod03_Sect06': ['multi model endpoint', 'deploy model amazon', 'prediction entire data', 'deploy train model', 'host multiple model', 'model create endpoint', 'entire data set', 'data processing step', 'prediction deploy model', 'model amazon sagemaker'], 'Mod02_Sect03': ['model training data', 'training data model', 'overfitting training data', 'time train model', 'model training model', 'train model training', 'age birth month', 'training data perform', 'model overfitting training', 'training model evaluation'], 'Mod06_Sect01': ['system convert text', 'convert text data', 'human machine interaction', 'task nlp application', 'form word run', 'natural language processing', 'system machine learning', 'inverse document frequency', 'number time word', 'form machine learning'], 'Mod05_Intro': ['great topic today', 'explore detail analyzing', 'analysis list step', 'list step required', 'sagemaker ground truth', 'recognition perform facial', 'detail analyzing image', 'academy machine learning', 'customized data set', 'data set performing'], 'Mod03_Sect01': ['machine learning model', 'machine learning pipeline', 'data machine learning', 'machine learning problem', 'credit card transaction', 'reduction number customer', 'machine learning', 'make prediction section', 'machine learning make', 'reminder machine learning'], 'Mod04_Sect02_part2': ['time series data', 'series data set', 'include time series', 'wrangling time series', 'random time series', 'face time series', 'independent time series', 'time series refer', 'excellent time series', 'handling time series'], 'Mod03_Sect02_part1': ['source data set', 'run training job', 'target answer prediction', 'data machine learning', 'credit card fraud', 'open source data', 'predict credit card', 'training job amazon', 'relational database service', 'training data amazon'], 'Mod02_WrapUp': ['artificial intelligence machine', 'part artificial intelligence', 'stage developing machine', 'discussing challenge machine', 'learned recognize machine', 'intelligence machine learning', 'intelligence describe artificial', 'describe artificial intelligence', 'artificial intelligence describe', 'machine learning'], 'Mod02_Sect02': ['machine learning program', 'reinforcement learning model', 'learning supervised learning', 'learning reinforcement learning', 'learning program trained', 'machine learning supervised', 'machine learning reinforcement', 'problem machine learning', 'machine learning problem', 'unsupervised machine learning'], 'Mod03_Sect04_part2': ['clean data set', 'data set missing', 'set missing data', 'variable describes number', 'missing data make', 'drop impute missing', 'missing data data', 'row missing data', 'missing data drop', 'missing data decide'], 'Mod02_Sect04': ['machine learning framework', 'open source machine', 'lab open source', 'machine learning', 'source machine learning', 'notebook open source', 'open source web', 'open source python', 'computing machine learning', 'jupiter lab open'], 'Mod03_Sect04_part3': ['box plot show', 'feature selection method', 'selection start feature', 'feature training model', 'plot box plot', 'method embedded method', 'method filter method', 'selection method filter', 'box plot box', 'method involve training'], 'Mod05_Sect03_part3': ['amazon recognition custom', 'recognition custom label', 'test data set', 'entire test data', 'custom label return', 'custom label test', 'image test data', 'metric entire test', 'presence custom label', 'custom label present'], 'Mod04_Sect02_part3': ['time series data', 'quantile predicts time', 'predicts time true', 'time fewer pair', 'fewer pair sold', 'amazon forecast create', 'amazon forecast train', 'sold time fewer', 'pair sold time', 'weighted quantile loss'], 'Mod01_Course Overview': ['machine learning pipeline', 'machine learning section', 'machine learning', 'machine learning problem', 'certified machine learning', 'statistic machine learning', 'implement machine learning', 'machine learning specialty', 'machine learning engineer', 'amazon machine learning'], 'Mod03_Intro': ['machine learning model', 'machine learning pipeline', 'machine learning problem', 'amazon sagemaker outline', 'amazon sagemaker train', 'learning pipeline applied', 'academy machine learning', 'entire machine learning', 'handling machine learning', 'type machine learning'], 'Mod05_Sect02_part1_ver2': ['amazon recognition analyzes', 'result amazon recognition', 'recognition analyzes image', 'amazon recognition', 'recognition amazon recognition', 'image inappropriate content', 'amazon recognition amazon', 'image stored video', 'amazon recognition performs', 'video amazon recognition'], 'Mod05_Sect01_ver2': ['case computer vision', 'computer vision automated', 'computer vision technology', 'vision automated extraction', 'vision computer vision', 'computer vision computer', 'computer vision', 'automated extraction information', 'technology computer vision', 'vision technology computer'], 'Mod03_Sect02_part2': ['aws glue data', 'glue data catalog', 'catalog aws glue', 'aws glue', 'extract transform load', 'set aws glue', 'store aws glue', 'aws glue service', 'aws glue run', 'aws glue console'], 'Mod03_Sect03_part3': ['quantify linear relationship', 'weak linear relationship', 'linear relationship quantified', 'relationship indication linear', 'indication linear relationship', 'minus linear relationship', 'set quantify linear', 'proportional minus linear', 'strong weak linear', 'seaborne heat map'], 'Mod05_Sect03_part2': ['sagemaker ground truth', 'automated data labeling', 'amazon recognition custom', 'recognition custom label', 'label data set', 'data set data', 'labeling sagemaker ground', 'training data set', 'human label data', 'set data set'], 'Mod03_Sect07_part3': ['false positive rate', 'positive false positive', 'difference prediction actual', 'positive rate false', 'rate false positive', 'true positive rate', 'email message spam', 'sensitivity true positive', 'calculate false positive', 'false positive high'], 'Mod06_WrapUp': ['back time review', 'nlp good job', 'time review module', 'wrap summary module', 'review module wrap', 'module wrap summary', 'summary module learn', 'learn describe nlp', 'managed amazon service', 'amazon service describe'], 'Mod03_Sect07_part1': ['predicted label class', 'cat predicted class', 'class actual label', 'actual label class', 'label class cat', 'good outcome model', 'similarly actual label', 'label cat identified', 'comparison predicted class', 'predicted class matched'], 'Mod07_Sect01': ['certified machine learning', 'machine learning specialty', 'aws certified machine', 'academy machine learning', 'machine learning solution', 'implement machine learning', 'aws academy machine', 'completing aws academy', 'congratulation completing aws', 'machine learning'], 'Mod02_Sect01': ['machine learning subset', 'learning practitioner spend', 'building machine perform', 'artificial intelligence broad', 'machine deep learning', 'layer artificial neuron', 'intelligence machine learning', 'machine learning', 'algorithm statistical model', 'deep learning practitioner'], 'Mod03_Sect03_part1': ['correct data type', 'data frame row', 'visualize analyze data', 'frame row label', 'column data frame', 'load data frame', 'row column column', 'row label column', 'row column format', 'type load data']}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from os.path import splitext\n",
    "\n",
    "key_phrases_dict = {}\n",
    "\n",
    "for filename, key_phrases in zip(os.listdir(directory_path), key_phrases_list):\n",
    "    video_name = splitext(filename)[0] \n",
    "    key_phrases_dict[video_name] = key_phrases\n",
    "\n",
    "# Print the dictionary\n",
    "print(key_phrases_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Topic 1': ['learning', 'machine', 'data', 'use', 'amazon', 'aws', 'model', 'problem', 'module', 'also'], 'Topic 2': ['model', 'data', 'word', 'metric', 'need', 'learning', 'use', 'machine', 'also', 'could'], 'Topic 3': ['amazon', 'video', 'learning', 'machine', 'recognition', 'data', 'face', 'image', 'also', 'feature'], 'Topic 4': ['data', 'model', 'set', 'use', 'time', 'also', 'learning', 'example', 'image', 'feature'], 'Topic 5': ['image', 'label', 'data', 'model', 'amazon', 'use', 'set', 'custom', 'object', 'recognition'], 'Topic 6': ['data', 'learning', 'machine', 'correlation', 'use', 'aws', 'amazon', 'one', 'section', 'module'], 'Topic 7': ['machine', 'learning', 'data', 'model', 'problem', 'set', 'module', 'also', 'time', 'use'], 'Topic 8': ['data', 'amazon', 'use', 'model', 'label', 'also', 'machine', 'image', 'need', 'forecast'], 'Topic 9': ['data', 'amazon', 'learning', 'use', 'machine', 'image', 'example', 'model', 'set', 'label'], 'Topic 10': ['data', 'model', 'feature', 'correlation', 'variable', 'relationship', 'learning', 'machine', 'example', 'value'], 'Topic 11': ['data', 'missing', 'value', 'example', 'need', 'also', 'use', 'set', 'time', 'learning'], 'Topic 12': ['image', 'label', 'amazon', 'data', 'video', 'recognition', 'use', 'object', 'model', 'also'], 'Topic 13': ['data', 'learning', 'machine', 'model', 'use', 'problem', 'set', 'section', 'amazon', 'also'], 'Topic 14': ['model', 'data', 'use', 'metric', 'learning', 'machine', 'value', 'also', 'image', 'example'], 'Topic 15': ['model', 'data', 'training', 'feature', 'set', 'need', 'algorithm', 'value', 'time', 'use'], 'Topic 16': ['amazon', 'image', 'data', 'use', 'model', 'recognition', 'label', 'training', 'object', 'also'], 'Topic 17': ['model', 'use', 'data', 'time', 'metric', 'example', 'nlp', 'also', 'word', 'positive'], 'Topic 18': ['model', 'word', 'data', 'nlp', 'example', 'text', 'feature', 'use', 'using', 'algorithm'], 'Topic 19': ['data', 'sagemaker', 'use', 'training', 'model', 'algorithm', 'amazon', 'learning', 'set', 'test'], 'Topic 20': ['model', 'data', 'use', 'training', 'amazon', 'set', 'also', 'example', 'label', 'want'], 'Topic 21': ['data', 'model', 'use', 'module', 'problem', 'amazon', 'image', 'service', 'learning', 'value'], 'Topic 22': ['data', 'model', 'value', 'label', 'set', 'missing', 'image', 'amazon', 'example', 'use'], 'Topic 23': ['data', 'model', 'time', 'might', 'value', 'example', 'problem', 'set', 'missing', 'training'], 'Topic 24': ['data', 'amazon', 'value', 'time', 'example', 'word', 'used', 'model', 'use', 'also'], 'Topic 25': ['data', 'learning', 'machine', 'model', 'label', 'aws', 'use', 'amazon', 'test', 'training'], 'Topic 26': ['aws', 'exam', 'machine', 'learning', 'certification', 'certified', 'course', 'experience', 'cloud', 'also'], 'Topic 27': ['data', 'learning', 'model', 'machine', 'need', 'aws', 'also', 'example', 'use', 'glue'], 'Topic 28': ['amazon', 'learning', 'exam', 'machine', 'certification', 'aws', 'nlp', 'data', 'certified', 'service'], 'Topic 29': ['data', 'model', 'amazon', 'use', 'training', 'learning', 'set', 'sagemaker', 'example', 'algorithm'], 'Topic 30': ['image', 'label', 'data', 'model', 'use', 'learning', 'machine', 'object', 'set', 'amazon'], 'Topic 31': ['data', 'learning', 'machine', 'model', 'use', 'set', 'problem', 'section', 'amazon', 'image'], 'Topic 32': ['model', 'cat', 'data', 'metric', 'positive', 'number', 'identified', 'use', 'negative', 'example'], 'Topic 33': ['data', 'learning', 'model', 'amazon', 'machine', 'use', 'section', 'problem', 'also', 'need'], 'Topic 34': ['learning', 'machine', 'artificial', 'deep', 'neuron', 'network', 'output', 'model', 'task', 'layer'], 'Topic 35': ['data', 'amazon', 'time', 'also', 'model', 'use', 'video', 'recognition', 'value', 'image'], 'Topic 36': ['model', 'data', 'learning', 'machine', 'use', 'amazon', 'section', 'need', 'sagemaker', 'problem'], 'Topic 37': ['data', 'model', 'feature', 'value', 'example', 'need', 'use', 'amazon', 'also', 'make'], 'Topic 38': ['data', 'amazon', 'learning', 'machine', 'use', 'module', 'problem', 'also', 'forecast', 'service'], 'Topic 39': ['image', 'data', 'model', 'object', 'computer', 'use', 'also', 'vision', 'learning', 'example'], 'Topic 40': ['data', 'model', 'set', 'value', 'use', 'image', 'example', 'amazon', 'label', 'might'], 'Topic 41': ['data', 'image', 'amazon', 'label', 'recognition', 'model', 'use', 'example', 'object', 'training'], 'Topic 42': ['amazon', 'model', 'data', 'image', 'use', 'feature', 'set', 'label', 'used', 'also'], 'Topic 43': ['image', 'computer', 'vision', 'use', 'model', 'data', 'learning', 'object', 'example', 'problem'], 'Topic 44': ['data', 'model', 'machine', 'learning', 'amazon', 'need', 'set', 'training', 'use', 'feature'], 'Topic 45': ['data', 'learning', 'machine', 'model', 'feature', 'problem', 'value', 'example', 'might', 'variable'], 'Topic 46': ['data', 'learning', 'machine', 'use', 'aws', 'also', 'problem', 'model', 'amazon', 'service']}\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "def extract_topics(texts, num_topics=5, num_words=10):\n",
    "    \n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
    "    topics_words_list = []\n",
    "    for i in range(num_topics):\n",
    "        topic_words = [word for word, _ in lda_model.show_topic(i, topn=num_words)]\n",
    "        topics_words_list.append(topic_words)\n",
    "    return topics_words_list\n",
    "\n",
    "normalized_texts_list = [text.split() for text in normalized_texts]\n",
    "\n",
    "# Calling the function to extract topics\n",
    "topics = extract_topics(normalized_texts_list, num_topics=num_topics, num_words=num_words)\n",
    "\n",
    "topic_words_dict = {}\n",
    "for i, topic_words in enumerate(topics, start=1):\n",
    "    topic_words_dict[f\"Topic {i}\"] = topic_words\n",
    "\n",
    "print(topic_words_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mod04_Intro': ['learning', 'machine', 'data', 'use', 'amazon', 'aws', 'model', 'problem', 'module', 'also'], 'Mod03_Sect03_part2': ['model', 'data', 'word', 'metric', 'need', 'learning', 'use', 'machine', 'also', 'could'], 'Mod03_Sect08': ['amazon', 'video', 'learning', 'machine', 'recognition', 'data', 'face', 'image', 'also', 'feature'], 'Mod05_Sect03_part1': ['data', 'model', 'set', 'use', 'time', 'also', 'learning', 'example', 'image', 'feature'], 'Mod04_WrapUp': ['image', 'label', 'data', 'model', 'amazon', 'use', 'set', 'custom', 'object', 'recognition'], 'Mod06_Sect02': ['data', 'learning', 'machine', 'correlation', 'use', 'aws', 'amazon', 'one', 'section', 'module'], 'Mod03_WrapUp': ['machine', 'learning', 'data', 'model', 'problem', 'set', 'module', 'also', 'time', 'use'], 'Mod04_Sect02_part1': ['data', 'amazon', 'use', 'model', 'label', 'also', 'machine', 'image', 'need', 'forecast'], 'Mod02_Intro': ['data', 'amazon', 'learning', 'use', 'machine', 'image', 'example', 'model', 'set', 'label'], 'Mod04_Sect01': ['data', 'model', 'feature', 'correlation', 'variable', 'relationship', 'learning', 'machine', 'example', 'value'], 'Mod03_Sect02_part3': ['data', 'missing', 'value', 'example', 'need', 'also', 'use', 'set', 'time', 'learning'], 'Mod05_Sect02_part2': ['image', 'label', 'amazon', 'data', 'video', 'recognition', 'use', 'object', 'model', 'also'], 'Mod02_Sect05': ['data', 'learning', 'machine', 'model', 'use', 'problem', 'set', 'section', 'amazon', 'also'], 'Mod05_Sect03_part4_ver2': ['model', 'data', 'use', 'metric', 'learning', 'machine', 'value', 'also', 'image', 'example'], 'Mod03_Sect05': ['model', 'data', 'training', 'feature', 'set', 'need', 'algorithm', 'value', 'time', 'use'], 'Mod06_Intro': ['amazon', 'image', 'data', 'use', 'model', 'recognition', 'label', 'training', 'object', 'also'], 'Mod05_WrapUp_ver2': ['model', 'use', 'data', 'time', 'metric', 'example', 'nlp', 'also', 'word', 'positive'], 'Mod03_Sect07_part2': ['model', 'word', 'data', 'nlp', 'example', 'text', 'feature', 'use', 'using', 'algorithm'], 'Mod03_Sect04_part1': ['data', 'sagemaker', 'use', 'training', 'model', 'algorithm', 'amazon', 'learning', 'set', 'test'], 'Mod03_Sect06': ['model', 'data', 'use', 'training', 'amazon', 'set', 'also', 'example', 'label', 'want'], 'Mod02_Sect03': ['data', 'model', 'use', 'module', 'problem', 'amazon', 'image', 'service', 'learning', 'value'], 'Mod06_Sect01': ['data', 'model', 'value', 'label', 'set', 'missing', 'image', 'amazon', 'example', 'use'], 'Mod05_Intro': ['data', 'model', 'time', 'might', 'value', 'example', 'problem', 'set', 'missing', 'training'], 'Mod03_Sect01': ['data', 'amazon', 'value', 'time', 'example', 'word', 'used', 'model', 'use', 'also'], 'Mod04_Sect02_part2': ['data', 'learning', 'machine', 'model', 'label', 'aws', 'use', 'amazon', 'test', 'training'], 'Mod03_Sect02_part1': ['aws', 'exam', 'machine', 'learning', 'certification', 'certified', 'course', 'experience', 'cloud', 'also'], 'Mod02_WrapUp': ['data', 'learning', 'model', 'machine', 'need', 'aws', 'also', 'example', 'use', 'glue'], 'Mod02_Sect02': ['amazon', 'learning', 'exam', 'machine', 'certification', 'aws', 'nlp', 'data', 'certified', 'service'], 'Mod03_Sect04_part2': ['data', 'model', 'amazon', 'use', 'training', 'learning', 'set', 'sagemaker', 'example', 'algorithm'], 'Mod02_Sect04': ['image', 'label', 'data', 'model', 'use', 'learning', 'machine', 'object', 'set', 'amazon'], 'Mod03_Sect04_part3': ['data', 'learning', 'machine', 'model', 'use', 'set', 'problem', 'section', 'amazon', 'image'], 'Mod05_Sect03_part3': ['model', 'cat', 'data', 'metric', 'positive', 'number', 'identified', 'use', 'negative', 'example'], 'Mod04_Sect02_part3': ['data', 'learning', 'model', 'amazon', 'machine', 'use', 'section', 'problem', 'also', 'need'], 'Mod01_Course Overview': ['learning', 'machine', 'artificial', 'deep', 'neuron', 'network', 'output', 'model', 'task', 'layer'], 'Mod03_Intro': ['data', 'amazon', 'time', 'also', 'model', 'use', 'video', 'recognition', 'value', 'image'], 'Mod05_Sect02_part1_ver2': ['model', 'data', 'learning', 'machine', 'use', 'amazon', 'section', 'need', 'sagemaker', 'problem'], 'Mod05_Sect01_ver2': ['data', 'model', 'feature', 'value', 'example', 'need', 'use', 'amazon', 'also', 'make'], 'Mod03_Sect02_part2': ['data', 'amazon', 'learning', 'machine', 'use', 'module', 'problem', 'also', 'forecast', 'service'], 'Mod03_Sect03_part3': ['image', 'data', 'model', 'object', 'computer', 'use', 'also', 'vision', 'learning', 'example'], 'Mod05_Sect03_part2': ['data', 'model', 'set', 'value', 'use', 'image', 'example', 'amazon', 'label', 'might'], 'Mod03_Sect07_part3': ['data', 'image', 'amazon', 'label', 'recognition', 'model', 'use', 'example', 'object', 'training'], 'Mod06_WrapUp': ['amazon', 'model', 'data', 'image', 'use', 'feature', 'set', 'label', 'used', 'also'], 'Mod03_Sect07_part1': ['image', 'computer', 'vision', 'use', 'model', 'data', 'learning', 'object', 'example', 'problem'], 'Mod07_Sect01': ['data', 'model', 'machine', 'learning', 'amazon', 'need', 'set', 'training', 'use', 'feature'], 'Mod02_Sect01': ['data', 'learning', 'machine', 'model', 'feature', 'problem', 'value', 'example', 'might', 'variable'], 'Mod03_Sect03_part1': ['data', 'learning', 'machine', 'use', 'aws', 'also', 'problem', 'model', 'amazon', 'service']}\n"
     ]
    }
   ],
   "source": [
    "from os.path import splitext\n",
    "\n",
    "# Create a dictionary to store topic words\n",
    "topic_words_dict = {}\n",
    "\n",
    "\n",
    "for filename, topic_words in zip(os.listdir(directory_path), topics):\n",
    "    file_name_without_extension = splitext(filename)[0]\n",
    "    topic_words_dict[file_name_without_extension] = topic_words\n",
    "\n",
    "\n",
    "print(topic_words_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import splitext, join\n",
    "\n",
    "# Define the directory paths to save key phrases and topics\n",
    "key_phrases_dir = \"key_phrases\"\n",
    "topics_dir = \"topics\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(key_phrases_dir, exist_ok=True)\n",
    "os.makedirs(topics_dir, exist_ok=True)\n",
    "\n",
    "# Save key phrases for each text\n",
    "for filename, key_phrases in zip(os.listdir(directory_path), key_phrases_list):\n",
    "    file_name_without_extension = splitext(filename)[0]\n",
    "    key_phrases_file_path = join(key_phrases_dir, f\"{file_name_without_extension}.txt\")\n",
    "    with open(key_phrases_file_path, 'w') as f:\n",
    "        for phrase in key_phrases:\n",
    "            f.write(f\"{phrase}\\n\")\n",
    "\n",
    "# Save topics for each text\n",
    "for filename, topics_tuple in zip(os.listdir(directory_path), topics_list):\n",
    "    file_name_without_extension = splitext(filename)[0]\n",
    "    topics_file_path = join(topics_dir, f\"{file_name_without_extension}.txt\")\n",
    "    with open(topics_file_path, 'w') as f:\n",
    "        for topic_id, topic in enumerate(topics_tuple, start=1):\n",
    "            f.write(f\"Topic {topic_id}:\\n{topic}\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.26.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (5.3.0)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.110.1)\n",
      "Requirement already satisfied: ffmpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.15.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.22.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.8.3)\n",
      "Requirement already satisfied: numpy~=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (1.22.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (3.10.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (21.3)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.7.0)\n",
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.3.7)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio) (0.29.0)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio-client==0.15.1->gradio) (2024.2.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gradio-client==0.15.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.21.1)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.18.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (13.7.0)\n",
      "\u001b[33mWARNING: typer 0.12.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fastapi->gradio) (0.37.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (2.17.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c1916c7b0c464b972519d7321a16ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', placeholder='Enter keyword or topic'), Button(description='Search', style=Button…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Video, HTML\n",
    "\n",
    "# Function to search for matching videos based on query\n",
    "def search_videos(query):\n",
    "    key_phrases_dir = \"key_phrases\"\n",
    "    topics_dir = \"topics\"\n",
    "    matching_videos = set()  \n",
    "\n",
    "    for file_name in os.listdir(key_phrases_dir):\n",
    "        file_path = os.path.join(key_phrases_dir, file_name)\n",
    "        if os.path.isfile(file_path):  \n",
    "            with open(file_path, \"r\") as file:\n",
    "                text_name = os.path.splitext(file_name)[0]\n",
    "                for line in file:\n",
    "                    if query in line:\n",
    "                        video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                        matching_videos.add((video_path, text_name))\n",
    "\n",
    "    for file_name in os.listdir(topics_dir):\n",
    "        file_path = os.path.join(topics_dir, file_name)\n",
    "        if os.path.isfile(file_path):  \n",
    "            with open(file_path, \"r\") as file:\n",
    "                text_name = os.path.splitext(file_name)[0]\n",
    "                for line in file:\n",
    "                    if query in line:\n",
    "                        video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                        matching_videos.add((video_path, text_name))\n",
    "\n",
    "    return list(matching_videos)\n",
    "\n",
    "# Function to display video players\n",
    "def display_video_players(matching_videos):\n",
    "    if matching_videos:\n",
    "        for video_path, video_name in matching_videos:\n",
    "            display(HTML(f\"<h3>{video_name}</h3>\"))\n",
    "            display(Video(video_path))\n",
    "    else:\n",
    "        print(\"No matching videos found.\")\n",
    "\n",
    "# Callback function for the search button\n",
    "def search_and_display_videos(btn):\n",
    "    output_videos.clear_output()  # Clear previous search results\n",
    "    query = text_input.value.strip()\n",
    "    if query:\n",
    "        matching_videos = search_videos(query)\n",
    "        with output_videos:\n",
    "            display_video_players(matching_videos)\n",
    "\n",
    "text_input = widgets.Text(placeholder=\"Enter keyword or topic\")\n",
    "\n",
    "search_button = widgets.Button(description=\"Search\")\n",
    "\n",
    "output_videos = widgets.Output()\n",
    "\n",
    "search_button.on_click(search_and_display_videos)\n",
    "\n",
    "display(widgets.VBox([text_input, search_button, output_videos]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7872\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://2cfd777c36aa34d3b0.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2cfd777c36aa34d3b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Function to search for matching videos based on query\n",
    "def search_videos(query):\n",
    "\n",
    "    key_phrases_dir = \"key_phrases\"\n",
    "    topics_dir = \"topics\"\n",
    "    matching_videos = []\n",
    "\n",
    "    # Searching for matching videos based on key phrases\n",
    "    for file_path in glob.glob(os.path.join(key_phrases_dir, \"*.txt\")):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            for line in file:\n",
    "                if query in line:\n",
    "                    video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                    matching_videos.append(video_path)\n",
    "\n",
    "    # Searching for matching videos based on topics\n",
    "    for file_path in glob.glob(os.path.join(topics_dir, \"*.txt\")):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            for line in file:\n",
    "                if (query in line) and text_name not in matching_videos:\n",
    "                    video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                    matching_videos.append(video_path)\n",
    "\n",
    "    return matching_videos\n",
    "\n",
    "# Function to display videos in Gradio interface\n",
    "def display_videos(matching_videos):\n",
    "    if matching_videos:\n",
    "        videos_data = []\n",
    "        for video_path in matching_videos:\n",
    "            video_name = os.path.basename(video_path)\n",
    "            videos_data.append((video_name, video_path))\n",
    "        return videos_data\n",
    "    else:\n",
    "        return \"No matching videos found.\"\n",
    "\n",
    "# Create a Gradio interface for searching and displaying videos\n",
    "search = gr.Interface(fn=search_videos, inputs=\"text\", outputs=\"text\", title=\"Video Search\", description=\"Enter a keyword or topic to search for related videos.\")\n",
    "search.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7874\n",
      "Sagemaker notebooks may require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Running on public URL: https://ed47ef647bef22a60e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ed47ef647bef22a60e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div><video width=\"320\" height=\"240\" controls><source src=\"downloaded_videos/Mod02_Sect03.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "def search_videos(query):\n",
    "   \n",
    "    key_phrases_dir = \"key_phrases\"\n",
    "    topics_dir = \"topics\"\n",
    "    matching_videos = set()  \n",
    "\n",
    "    # Searching for matching videos based on key phrases\n",
    "    for file_path in glob.glob(os.path.join(key_phrases_dir, \"*.txt\")):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            for line in file:\n",
    "                if query in line:\n",
    "                    video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                    matching_videos.add(video_path)\n",
    "\n",
    "    # Searching for matching videos based on topics\n",
    "    for file_path in glob.glob(os.path.join(topics_dir, \"*.txt\")):\n",
    "        with open(file_path, \"r\") as file:\n",
    "            text_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "            for line in file:\n",
    "                if query in line:\n",
    "                    video_path = os.path.join(\"downloaded_videos\", f\"{text_name}.mp4\")\n",
    "                    matching_videos.add(video_path)\n",
    "\n",
    "    return list(matching_videos)\n",
    "\n",
    "# Function to display videos in HTML format\n",
    "def display_videos(matching_videos):\n",
    "    if matching_videos:\n",
    "        html = \"<div>\"\n",
    "        for video in matching_videos:\n",
    "            html += f'<video width=\"320\" height=\"240\" controls><source src=\"{video}\" type=\"video/mp4\"></video>'\n",
    "        html += \"</div>\"\n",
    "        display(HTML(html))\n",
    "    else:\n",
    "        print(\"No matching videos found.\")\n",
    "\n",
    "# Gradio interface for searching and displaying videos\n",
    "def search_and_display_videos(query):\n",
    "    matching_videos = search_videos(query)\n",
    "    display_videos(matching_videos)\n",
    "\n",
    "iface = gr.Interface(fn=search_and_display_videos, inputs=\"text\", outputs=None, title=\"Video Search\", description=\"Enter a keyword or topic to search for related videos.\")\n",
    "iface.launch(inline=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
